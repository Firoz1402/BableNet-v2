{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33588c85-0ed0-41fc-b288-a7ab727443f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import re\n",
    "import string\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574c4b4e-6562-4ffc-8148-2228dfffd5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89111de-9930-45c4-9c7d-58c38fd2b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=25000, random_state=42)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03551af-8832-4f67-ba40-79928ac93f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df=df[~pd.isnull(df['english_sentence'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75411f55-76f4-4407-99ca-4ff7554398fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.lower())\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.strip())\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.strip())\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e5e4be-4e90-4879-9cc7-431af0431bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hindi_sentence(sentence):\n",
    "    # Regular expression for Hindi numbers\n",
    "    hindi_numbers_pattern = '[०१२३४५६७८९]'\n",
    "    \n",
    "    # Regular expression for English words\n",
    "    english_words_pattern = r'\\b[a-zA-Z]+\\b'\n",
    "    \n",
    "    # Remove Hindi numbers\n",
    "    sentence = re.sub(hindi_numbers_pattern, '', sentence)\n",
    "    \n",
    "    # Remove English words\n",
    "    sentence = re.sub(english_words_pattern, '', sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Apply the function to the 'hindi_sentence' column\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(clean_hindi_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6169d1-2ea1-473f-b472-8a5acde2765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tides</td>\n",
       "      <td>he declares the result and reports it to the e...</td>\n",
       "      <td>वही परिणाम की घोषणा करता है और निर्वाचन आयोग क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>was a little uncomfortable for them</td>\n",
       "      <td>थोडा कठिन था।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>but mulla assamudin was proved to be not eligible</td>\n",
       "      <td>मगर मुल्ला असमुद्दीन अक्षम सिद्ध हुए।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>i would never have to make a book and then pre...</td>\n",
       "      <td>मुझे कभी भी किताब बना कर किसी प्रदर्शनस्थल को ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>headind kaun banega crorepati</td>\n",
       "      <td>शीर्षक कौन बनेगा करोड़पति</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0      tides  he declares the result and reports it to the e...   \n",
       "1        ted                was a little uncomfortable for them   \n",
       "2  indic2012  but mulla assamudin was proved to be not eligible   \n",
       "3        ted  i would never have to make a book and then pre...   \n",
       "4  indic2012                      headind kaun banega crorepati   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  वही परिणाम की घोषणा करता है और निर्वाचन आयोग क...  \n",
       "1                                      थोडा कठिन था।  \n",
       "2              मगर मुल्ला असमुद्दीन अक्षम सिद्ध हुए।  \n",
       "3  मुझे कभी भी किताब बना कर किसी प्रदर्शनस्थल को ...  \n",
       "4                       शीर्षक कौन बनेगा करोड़पति     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85162de2-e7a1-4919-abc6-8ce300956445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24698, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119fdd5-4240-4fd6-9ed3-d5a6918610b3",
   "metadata": {},
   "source": [
    "# Keeping the data with only sentences less than equal to  max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ad39ca-00a7-46e1-80ae-eb7c8527192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length_eng_sentence']=df['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "df['length_hin_sentence']=df['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94256f90-2a06-4d32-b5dd-508e446e1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['length_eng_sentence']<=20]\n",
    "df=df[df['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99562c87-40af-4d72-9ebb-9864e2af90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(df['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(df['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bcdb317-b4b4-4c48-8a4f-16cbd8da0ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17234, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa910f6e-2876-4a8d-a72d-27521214571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tides</td>\n",
       "      <td>he declares the result and reports it to the e...</td>\n",
       "      <td>वही परिणाम की घोषणा करता है और निर्वाचन आयोग क...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>was a little uncomfortable for them</td>\n",
       "      <td>थोडा कठिन था।</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>but mulla assamudin was proved to be not eligible</td>\n",
       "      <td>मगर मुल्ला असमुद्दीन अक्षम सिद्ध हुए।</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>i would never have to make a book and then pre...</td>\n",
       "      <td>मुझे कभी भी किताब बना कर किसी प्रदर्शनस्थल को ...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>headind kaun banega crorepati</td>\n",
       "      <td>शीर्षक कौन बनेगा करोड़पति</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0      tides  he declares the result and reports it to the e...   \n",
       "1        ted                was a little uncomfortable for them   \n",
       "2  indic2012  but mulla assamudin was proved to be not eligible   \n",
       "3        ted  i would never have to make a book and then pre...   \n",
       "4  indic2012                      headind kaun banega crorepati   \n",
       "\n",
       "                                      hindi_sentence  length_eng_sentence  \\\n",
       "0  वही परिणाम की घोषणा करता है और निर्वाचन आयोग क...                   19   \n",
       "1                                      थोडा कठिन था।                    6   \n",
       "2              मगर मुल्ला असमुद्दीन अक्षम सिद्ध हुए।                    9   \n",
       "3  मुझे कभी भी किताब बना कर किसी प्रदर्शनस्थल को ...                   15   \n",
       "4                       शीर्षक कौन बनेगा करोड़पति                       4   \n",
       "\n",
       "   length_hin_sentence  \n",
       "0                   20  \n",
       "1                    3  \n",
       "2                    6  \n",
       "3                   14  \n",
       "4                    7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d6e2b5-c56f-490c-8e41-2cdc27b84ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns\n",
    "df = df.drop(['length_hin_sentence', 'length_eng_sentence'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24bade7-e09a-4755-8b2a-52cf2dd85270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tides</td>\n",
       "      <td>he declares the result and reports it to the e...</td>\n",
       "      <td>वही परिणाम की घोषणा करता है और निर्वाचन आयोग क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>was a little uncomfortable for them</td>\n",
       "      <td>थोडा कठिन था।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>but mulla assamudin was proved to be not eligible</td>\n",
       "      <td>मगर मुल्ला असमुद्दीन अक्षम सिद्ध हुए।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>i would never have to make a book and then pre...</td>\n",
       "      <td>मुझे कभी भी किताब बना कर किसी प्रदर्शनस्थल को ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>headind kaun banega crorepati</td>\n",
       "      <td>शीर्षक कौन बनेगा करोड़पति</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0      tides  he declares the result and reports it to the e...   \n",
       "1        ted                was a little uncomfortable for them   \n",
       "2  indic2012  but mulla assamudin was proved to be not eligible   \n",
       "3        ted  i would never have to make a book and then pre...   \n",
       "4  indic2012                      headind kaun banega crorepati   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  वही परिणाम की घोषणा करता है और निर्वाचन आयोग क...  \n",
       "1                                      थोडा कठिन था।  \n",
       "2              मगर मुल्ला असमुद्दीन अक्षम सिद्ध हुए।  \n",
       "3  मुझे कभी भी किताब बना कर किसी प्रदर्शनस्थल को ...  \n",
       "4                       शीर्षक कौन बनेगा करोड़पति     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779eaa1d-d024-437f-8f1b-a24fe81cec89",
   "metadata": {},
   "source": [
    "# Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "374f9554-04d6-4369-8366-08196f4b9671",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(padded_tokens), torch\u001b[38;5;241m.\u001b[39mtensor(attention_masks)\n\u001b[1;32m     16\u001b[0m MAX_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 18\u001b[0m english_tokens, english_attention_masks \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_and_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish_sentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m hindi_tokens, hindi_attention_masks \u001b[38;5;241m=\u001b[39m tokenize_and_pad(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhindi_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), hindi_tokenizer, MAX_LEN)\n",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m, in \u001b[0;36mtokenize_and_pad\u001b[0;34m(sentences, tokenizer, max_len)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_and_pad\u001b[39m(sentences, tokenizer, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m     11\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mencode(sentence, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[0;32m---> 12\u001b[0m     padded_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequences\u001b[49m(tokens, maxlen\u001b[38;5;241m=\u001b[39mmax_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     attention_masks \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mint\u001b[39m(token_id \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m token_id \u001b[38;5;129;01min\u001b[39;00m token_seq] \u001b[38;5;28;01mfor\u001b[39;00m token_seq \u001b[38;5;129;01min\u001b[39;00m padded_tokens]\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(padded_tokens), torch\u001b[38;5;241m.\u001b[39mtensor(attention_masks)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizers for English and Hindi\n",
    "english_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "hindi_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Tokenize the sentences\n",
    "df['english_tokens'] = df['english_sentence'].apply(lambda x: english_tokenizer.encode(x, add_special_tokens=True))\n",
    "df['hindi_tokens'] = df['hindi_sentence'].apply(lambda x: hindi_tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# Tokenize the sentences\n",
    "def tokenize_and_pad(sentences, tokenizer, max_len=50):\n",
    "    tokens = [tokenizer.encode(sentence, add_special_tokens=True) for sentence in sentences]\n",
    "    padded_tokens = pad_sequences(tokens, maxlen=max_len, padding='post')\n",
    "    attention_masks = [[int(token_id > 0) for token_id in token_seq] for token_seq in padded_tokens]\n",
    "    return torch.tensor(padded_tokens), torch.tensor(attention_masks)\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "english_tokens, english_attention_masks = tokenize_and_pad(df['english_sentence'].tolist(), english_tokenizer, MAX_LEN)\n",
    "hindi_tokens, hindi_attention_masks = tokenize_and_pad(df['hindi_sentence'].tolist(), hindi_tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16a1ab-4252-4066-983d-bd6737952300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ad37e-9399-4aef-8092-e3dc67c48547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(tokens, attention_masks, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens, attention_mask=attention_masks)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "# Load pre-trained BERT models\n",
    "english_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "hindi_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Generate embeddings for each sentence\n",
    "english_embeddings = get_embeddings(english_tokens, english_attention_masks, english_model)\n",
    "hindi_embeddings = get_embeddings(hindi_tokens, hindi_attention_masks, hindi_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf9d46-4654-422e-858b-504633d3d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=8), num_layers=3)\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=output_dim, nhead=8), num_layers=3)\n",
    "        self.fc = nn.Linear(output_dim, hidden_dim)\n",
    "        self.output_fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        memory = self.encoder(src)\n",
    "        output = self.decoder(tgt, memory)\n",
    "        output = self.fc(output)\n",
    "        output = self.output_fc(output)\n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "input_dim = 768  # BERT embeddings dimension\n",
    "output_dim = 768\n",
    "hidden_dim = 512\n",
    "model = Seq2SeqModel(input_dim, output_dim, hidden_dim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
