{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "lines=pd.read_csv(\"../data/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what needs to be done.</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the percentage in India.</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not paying attention.</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called Upanishad.</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tides</td>\n",
       "      <td>The then Governor of Kashmir resisted transfer , but was finally reduced to subjection with the aid of British .</td>\n",
       "      <td>कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का विरोध किया था , लेकिन अंग्रेजों की सहायता से उनकी आवाज दबा दी गयी .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>In this lies the circumstances of people before you.</td>\n",
       "      <td>इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>“”Global Warming“” refer to warming caused in recent decades and probability of its continual presence and its indirect effect on human being.</td>\n",
       "      <td>ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई वार्मिंग और इसके निरंतर बने रहने के अनुमान और इसके अप्रत्यक्ष रूप से मानव पर पड़ने वाले प्रभाव से है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tides</td>\n",
       "      <td>You may want your child to go to a school that is not run by the LEA - a non-maintained special school or an independent school that can meet your child 's needs .</td>\n",
       "      <td>हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटेन्ड ह्यबिना किसी समर्थन के हृ विशेष स्कूल , या किसी स्वतंत्र स्कूल में जाए , इजसके पास विशेष शैक्षणिक जऋऋरतों वाले बच्चों के प्रति सहूलियत हों . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tides</td>\n",
       "      <td>Please ensure that you use the appropriate form .</td>\n",
       "      <td>कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प्रयोग कर रहें हैं .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Category: Religious Text</td>\n",
       "      <td>श्रेणी:धर्मग्रन्थ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This period summarily is pepped up with devotion.</td>\n",
       "      <td>यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tides</td>\n",
       "      <td>The first two were found unreliable and the prosecution case rested mainly on the evidence of the remaining five approvers .</td>\n",
       "      <td>पहले दो को अविश्वसनीय मानकर बाकी पांच मुखबिरों के आधार पर मुकदमा चलाया गया .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tides</td>\n",
       "      <td>They had justified their educational policy of concentrating on the education of a small number of upper and middle-class people with the argument that the new education would gradually ' filter down ' from above .</td>\n",
       "      <td>कम संख़्या वाले उच्च एवं मध्यम श्रेणी के लोगों तक ही अपनी शिक्षा नीति को केंद्रित करने को इस तर्क के साथ न्यायसंगत बताया कि नयी शिक्षा Zक्रमश : ऊपर से नीचे की ओर छनते हुए जायेगी .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>And now at present the naturecure, Ayurvedic and modern treatments are taking place through the government in Nepal.</td>\n",
       "      <td>हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प्राकृतिक चिकित्सा तथा आधुनिक चिकीत्सा करके सरकारी सेवा विद्यमान हे ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Parliament time frame is 5 years and this will be dissolved before that.</td>\n",
       "      <td>लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय से पूर्व भंग किया जा सकता है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tides</td>\n",
       "      <td>ii Register Courts , empowered to try causes for amounts not exceeding Rs 200 , when authorised by the judges .</td>\n",
       "      <td>रजिस्टर न्यायालय जिन्हें न्यायाधीश द्वारा प्राधिकृत किए जाने पर 200 रु . तक के वादों का निर्णय करने का अधिकार था .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Extreme weather due to increased mortality; displacements and economic loss will be compounded through growing population. Although, temperate climate has some benefits out of it such as decreased mortality due to cold weather.</td>\n",
       "      <td>बढ़ती हुई मौतों displacements और आर्थिक नुकसान जो की अतिवादी मौसम (extreme weather)के कारण संभावित हैं बढती हुई जनसँख्या (growing population)के कारण और भी बदतर हो सकते हैं . हालांकि शीतोष्ण क्षेत्र में इसके कुछ फैदे भी हो सकते हैं जैसे की ठंड की वजह से कम मौतें होना .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                                                                                                                                                                                                     english_sentence                                                                                                                                                                                                                                                                hindi_sentence\n",
       "0   ted        politicians do not have permission to do what needs to be done.                                                                                                                                                                      राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .                                                                                                                                                                                                        \n",
       "1   ted        I'd like to tell you about one such child,                                                                                                                                                                                           मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                                                                                                                                                                                                                          \n",
       "2   indic2012  This percentage is even greater than the percentage in India.                                                                                                                                                                        यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।                                                                                                                                                                                                                            \n",
       "3   ted        what we really mean is that they're bad at not paying attention.                                                                                                                                                                     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                                                                                                                                                                                                                              \n",
       "4   indic2012  .The ending portion of these Vedas is called Upanishad.                                                                                                                                                                              इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।                                                                                                                                                                                                                                 \n",
       "5   tides      The then Governor of Kashmir resisted transfer , but was finally reduced to subjection with the aid of British .                                                                                                                     कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का विरोध किया था , लेकिन अंग्रेजों की सहायता से उनकी आवाज दबा दी गयी .                                                                                                                                                            \n",
       "6   indic2012  In this lies the circumstances of people before you.                                                                                                                                                                                 इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।                                                                                                                                                                                                                            \n",
       "7   ted        And who are we to say, even, that they are wrong                                                                                                                                                                                     और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                                                                                                                                                                                                                            \n",
       "8   indic2012  “”Global Warming“” refer to warming caused in recent decades and probability of its continual presence and its indirect effect on human being.                                                                                       ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई वार्मिंग और इसके निरंतर बने रहने के अनुमान और इसके अप्रत्यक्ष रूप से मानव पर पड़ने वाले प्रभाव से है।                                                                                                                        \n",
       "9   tides      You may want your child to go to a school that is not run by the LEA - a non-maintained special school or an independent school that can meet your child 's needs .                                                                  हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटेन्ड ह्यबिना किसी समर्थन के हृ विशेष स्कूल , या किसी स्वतंत्र स्कूल में जाए , इजसके पास विशेष शैक्षणिक जऋऋरतों वाले बच्चों के प्रति सहूलियत हों . .                                                                            \n",
       "10  tides      Please ensure that you use the appropriate form .                                                                                                                                                                                    कृपया यह सुनिश्चित कर लें कि आप सही फॉर्म का प्रयोग कर रहें हैं .                                                                                                                                                                                                           \n",
       "11  indic2012  Category: Religious Text                                                                                                                                                                                                             श्रेणी:धर्मग्रन्थ                                                                                                                                                                                                                                                           \n",
       "12  indic2012  This period summarily is pepped up with devotion.                                                                                                                                                                                    यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।                                                                                                                                                                                                                               \n",
       "13  ted        So there is some sort of justice                                                                                                                                                                                                     तो वहाँ न्याय है                                                                                                                                                                                                                                                            \n",
       "14  tides      The first two were found unreliable and the prosecution case rested mainly on the evidence of the remaining five approvers .                                                                                                         पहले दो को अविश्वसनीय मानकर बाकी पांच मुखबिरों के आधार पर मुकदमा चलाया गया .                                                                                                                                                                                                \n",
       "15  tides      They had justified their educational policy of concentrating on the education of a small number of upper and middle-class people with the argument that the new education would gradually ' filter down ' from above .               कम संख़्या वाले उच्च एवं मध्यम श्रेणी के लोगों तक ही अपनी शिक्षा नीति को केंद्रित करने को इस तर्क के साथ न्यायसंगत बताया कि नयी शिक्षा Zक्रमश : ऊपर से नीचे की ओर छनते हुए जायेगी .                                                                                         \n",
       "16  indic2012  And now at present the naturecure, Ayurvedic and modern treatments are taking place through the government in Nepal.                                                                                                                 हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प्राकृतिक चिकित्सा तथा आधुनिक चिकीत्सा करके सरकारी सेवा विद्यमान हे ।                                                                                                                                                          \n",
       "17  indic2012  Parliament time frame is 5 years and this will be dissolved before that.                                                                                                                                                             लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय से पूर्व भंग किया जा सकता है                                                                                                                                                                                                   \n",
       "18  tides      ii Register Courts , empowered to try causes for amounts not exceeding Rs 200 , when authorised by the judges .                                                                                                                      रजिस्टर न्यायालय जिन्हें न्यायाधीश द्वारा प्राधिकृत किए जाने पर 200 रु . तक के वादों का निर्णय करने का अधिकार था .                                                                                                                                                          \n",
       "19  indic2012  Extreme weather due to increased mortality; displacements and economic loss will be compounded through growing population. Although, temperate climate has some benefits out of it such as decreased mortality due to cold weather.  बढ़ती हुई मौतों displacements और आर्थिक नुकसान जो की अतिवादी मौसम (extreme weather)के कारण संभावित हैं बढती हुई जनसँख्या (growing population)के कारण और भी बदतर हो सकते हैं . हालांकि शीतोष्ण क्षेत्र में इसके कुछ फैदे भी हो सकते हैं जैसे की ठंड की वजह से कम मौतें होना ."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    2\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[~pd.isnull(lines['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=lines.sample(n=50000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45291"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'laddaki',\n",
       " 'multiplying',\n",
       " 'madina',\n",
       " 'fowlpox',\n",
       " 'shower',\n",
       " 'hamida',\n",
       " 'hatmakers',\n",
       " 'tie',\n",
       " 'hoarse',\n",
       " 'offending',\n",
       " 'fernandes',\n",
       " 'severalfolds',\n",
       " 'diphtheria',\n",
       " 'cares',\n",
       " 'bowlsecond',\n",
       " 'fright',\n",
       " 'shooters',\n",
       " 'altruism',\n",
       " 'angry',\n",
       " 'resettlement',\n",
       " 'bandits',\n",
       " 'mediators',\n",
       " 'injury',\n",
       " 'marked',\n",
       " 'tantric',\n",
       " 'udf',\n",
       " 'bowledthe',\n",
       " 'mindonly',\n",
       " 'indira',\n",
       " 'necessitated',\n",
       " '“ah',\n",
       " 'thakurbanglaravindra',\n",
       " 'namangani',\n",
       " 'dhavanmarg',\n",
       " 'retirement',\n",
       " 'ishwaray',\n",
       " 'melts',\n",
       " 'interspaces',\n",
       " 'bot',\n",
       " 'occasions',\n",
       " 'groundfloor',\n",
       " 'adversely',\n",
       " 'jiyauddeen',\n",
       " 'nausea',\n",
       " 'trumpets',\n",
       " 'preshyat',\n",
       " 'seventytwo',\n",
       " 'fearful',\n",
       " 'detection',\n",
       " 'clings',\n",
       " 'disproportionate',\n",
       " 'racialism',\n",
       " 'itselffrom',\n",
       " 'especially',\n",
       " 'distributions',\n",
       " 'raid',\n",
       " 'nagarjun',\n",
       " 'cramped',\n",
       " 'distinguished',\n",
       " 'friedrich',\n",
       " 'celibacy',\n",
       " 'illustrations',\n",
       " 'corbelled',\n",
       " 'hal',\n",
       " 'hadapa',\n",
       " 'introspective',\n",
       " 'oy',\n",
       " 'prosodic',\n",
       " 'amounted',\n",
       " 'powergenerating',\n",
       " 'doubling',\n",
       " 'clearwater',\n",
       " 'tapas',\n",
       " 'panjam',\n",
       " 'thrown',\n",
       " 'gdr',\n",
       " 'ness',\n",
       " 'subordination',\n",
       " 'kansa',\n",
       " 'brihanmumbai',\n",
       " 'albis',\n",
       " 'statechief',\n",
       " 'horseshoe',\n",
       " 'arab',\n",
       " 'gate',\n",
       " 'gettogether',\n",
       " '“',\n",
       " 'beatrices',\n",
       " 'ejecting',\n",
       " 'priceless',\n",
       " 'deeply',\n",
       " 'morals',\n",
       " 'swings',\n",
       " 'damm',\n",
       " 'pentagon',\n",
       " 'panchamahasabda',\n",
       " 'pursuit',\n",
       " 'achievement',\n",
       " 'atarva',\n",
       " 'unwanted',\n",
       " 'shigeru',\n",
       " 'downsized',\n",
       " 'shoes',\n",
       " 'yuan',\n",
       " 'soldthe',\n",
       " 'clout',\n",
       " 'aside',\n",
       " 'palms',\n",
       " 'shifting',\n",
       " 'romanian',\n",
       " 'nucleus',\n",
       " 'phallic',\n",
       " 'chips',\n",
       " 'wicketkeepers',\n",
       " 'madivala',\n",
       " 'fog',\n",
       " 'selfgovernment',\n",
       " 'demarcate',\n",
       " 'presidentchairman',\n",
       " 'countered',\n",
       " 'alluvial',\n",
       " 'prof',\n",
       " 'challenger',\n",
       " 'displaying',\n",
       " 'declinations',\n",
       " 'patterned',\n",
       " 'ecosystems',\n",
       " 'deewan',\n",
       " 'beejak',\n",
       " 'intermittent',\n",
       " 'defame',\n",
       " 'explaination',\n",
       " 'travel',\n",
       " 'upperlowerleft',\n",
       " 'bhopal',\n",
       " 'resting',\n",
       " 'kahini',\n",
       " 'sandglass',\n",
       " 'successfulbody',\n",
       " 'thakre',\n",
       " 'baluchistan',\n",
       " 'ageold',\n",
       " 'handshence',\n",
       " 'garumara',\n",
       " 'drills',\n",
       " 'kaizen',\n",
       " 'angad',\n",
       " 'rahat',\n",
       " 'azaad',\n",
       " 'aptly',\n",
       " 'kaaba',\n",
       " 'sizeable',\n",
       " 'tarpo',\n",
       " 'grievance',\n",
       " 'laugh”',\n",
       " 'singularity',\n",
       " 'minakshisundaresvara',\n",
       " 'active',\n",
       " 'karma',\n",
       " 'velocities',\n",
       " 'parisesh',\n",
       " 'nonstriker',\n",
       " 'tightened',\n",
       " 'pioneer',\n",
       " 'timeconsuming',\n",
       " 'television',\n",
       " 'photography',\n",
       " 'rightkascripto',\n",
       " 'unearthly',\n",
       " 'pig',\n",
       " 'khayams',\n",
       " 'midaction',\n",
       " 'silicosis',\n",
       " 'tailoring',\n",
       " 'cumulatively',\n",
       " 'newspaper',\n",
       " 'blades',\n",
       " 'indestructible',\n",
       " 'feast',\n",
       " 'willing',\n",
       " 'stanza',\n",
       " 'chaudhary',\n",
       " 'crown',\n",
       " 'contraceptive',\n",
       " 'drudging',\n",
       " 'receiverpleasure',\n",
       " 'trawlers',\n",
       " 'terror“”isbn',\n",
       " 'marseilles',\n",
       " 'hangover',\n",
       " 'facetoface',\n",
       " 'surge',\n",
       " 'twilight',\n",
       " 'europegermany',\n",
       " 'effort',\n",
       " 'atomsphere',\n",
       " 'scanner',\n",
       " 'bandit',\n",
       " 'storywriting',\n",
       " 'bitterly',\n",
       " 'bajpai',\n",
       " 'lostit',\n",
       " 'multinationals',\n",
       " 'judiciary',\n",
       " 'mahavira',\n",
       " 'lusting',\n",
       " 'horses',\n",
       " 'declination',\n",
       " 'dialects',\n",
       " 'lr',\n",
       " 'hindiurdu',\n",
       " 'brushing',\n",
       " 'revealedacquired',\n",
       " 'mayami',\n",
       " 'presidentelect',\n",
       " 'articulation',\n",
       " 'alkharismi',\n",
       " 'pushtu',\n",
       " 'ibrahim',\n",
       " 'passionate',\n",
       " 'watercolour',\n",
       " 'werner',\n",
       " 'billand',\n",
       " 'feudalism',\n",
       " 'throwaway',\n",
       " 'maharaj',\n",
       " 'muses',\n",
       " 'verdant',\n",
       " 'erudition',\n",
       " 'timber',\n",
       " 'lifesurplus',\n",
       " 'billions',\n",
       " 'cheapest',\n",
       " 'deities',\n",
       " 'misappropriation',\n",
       " 'aryelam',\n",
       " 'goonda',\n",
       " 'constitution',\n",
       " 'iaa',\n",
       " 'prospectively',\n",
       " 'signposting',\n",
       " 'pregrowing',\n",
       " 'sensing',\n",
       " 'armory',\n",
       " 'bleaching',\n",
       " 'shovelshaped',\n",
       " 'constructively',\n",
       " 'hiding',\n",
       " 'babbar',\n",
       " 'henpecked',\n",
       " 'lustre',\n",
       " 'toheed',\n",
       " 'deployments',\n",
       " 'alum',\n",
       " 'polytheism',\n",
       " 'hat',\n",
       " 'sho',\n",
       " 'dilli“”',\n",
       " 'irrigated',\n",
       " 'leftists',\n",
       " 'upgradation',\n",
       " 'medaiunder',\n",
       " 'plitical',\n",
       " 'disciplined',\n",
       " 'suddhodhan',\n",
       " 'comming',\n",
       " 'rafting',\n",
       " 'cdssa',\n",
       " 'sawdust',\n",
       " 'transfers',\n",
       " 'depot',\n",
       " 'heels',\n",
       " 'televised',\n",
       " 'subsidiary',\n",
       " 'hellto',\n",
       " 'earmarked',\n",
       " 'jed',\n",
       " 'molecules',\n",
       " 'languageawadhimaithilimarwadi',\n",
       " 'annie',\n",
       " 'charcoal',\n",
       " 'dangerlevel',\n",
       " 'fashion',\n",
       " 'mobilewhich',\n",
       " 'embraced',\n",
       " 'greece',\n",
       " 'cardiff',\n",
       " 'insists',\n",
       " 'minutest',\n",
       " 'chandhasa',\n",
       " 'rhythm',\n",
       " 'vaman',\n",
       " 'trouble',\n",
       " 'noman',\n",
       " 'cocoon',\n",
       " 'godallah',\n",
       " 'loktez',\n",
       " 'goebbelian',\n",
       " 'joke',\n",
       " 'punyaholy',\n",
       " 'elevates',\n",
       " 'gep',\n",
       " 'storage',\n",
       " 'confirming',\n",
       " 'recited',\n",
       " 'definition',\n",
       " 'srinivasanallur',\n",
       " 'gleam',\n",
       " 'blasts',\n",
       " 'havanthis',\n",
       " 'mokrfia',\n",
       " 'unesko',\n",
       " 'australias',\n",
       " 'concludes',\n",
       " 'bins',\n",
       " 'jasmins',\n",
       " 'onegodisum',\n",
       " 'polish',\n",
       " 'zindabad',\n",
       " 'erence',\n",
       " 'he',\n",
       " 'consisting',\n",
       " 'imagination',\n",
       " 'irani',\n",
       " 'caesar',\n",
       " 'diminutive',\n",
       " 'anthropogenicincreasing',\n",
       " 'handbags',\n",
       " 'executives',\n",
       " 'interferon',\n",
       " 'eatinghour',\n",
       " 'trig',\n",
       " 'candy',\n",
       " 'mount',\n",
       " 'bloodbath',\n",
       " 'kumizh',\n",
       " 'abdel',\n",
       " 'pearson',\n",
       " 'outright',\n",
       " 'queer',\n",
       " 'evergreen',\n",
       " 'basse',\n",
       " 'rapture',\n",
       " 'kw',\n",
       " 'naming',\n",
       " 'illustrated',\n",
       " 'lodia',\n",
       " 'peacocks',\n",
       " 'looks',\n",
       " 'attractiveness',\n",
       " 'panels',\n",
       " 'ainerence',\n",
       " 'synonymously',\n",
       " 'smashed',\n",
       " 'gurupreacher',\n",
       " 'sudershan',\n",
       " 'menfolk',\n",
       " 'shuangeri',\n",
       " 'hasslefree',\n",
       " 'chromosomal',\n",
       " 'sskathyayaँ',\n",
       " 'kapada',\n",
       " '‘deep',\n",
       " 'hydrogenated',\n",
       " 'chitrangadha',\n",
       " 'melodies',\n",
       " 'antiperspirant',\n",
       " 'remorse',\n",
       " 'naachghar',\n",
       " 'bhaiya',\n",
       " 'pamphlet',\n",
       " 'flashlight',\n",
       " 'maliciously',\n",
       " 'kanharawa',\n",
       " 'anantasayanagudi',\n",
       " 'avatarand',\n",
       " 'supremacy',\n",
       " 'wyllie',\n",
       " 'bunions',\n",
       " 'arb',\n",
       " 'inches',\n",
       " 'brahmagana',\n",
       " 'downgrade',\n",
       " 'routes',\n",
       " 'children',\n",
       " 'doomed',\n",
       " 'beside',\n",
       " 'nahare',\n",
       " 'rogi',\n",
       " 'opera',\n",
       " 'reinforcements',\n",
       " 'hoot',\n",
       " 'poster',\n",
       " 'scanned',\n",
       " 'breathtakingly',\n",
       " 'bawori',\n",
       " '“”your',\n",
       " 'junior',\n",
       " 'compressed',\n",
       " 'abridge',\n",
       " 'mohinuddin',\n",
       " 'udisi',\n",
       " 'youre',\n",
       " 'virginity',\n",
       " 'nahyan',\n",
       " 'accessed',\n",
       " 'taping',\n",
       " 'bjp',\n",
       " 'sikandara',\n",
       " 'weve',\n",
       " 'eruptions',\n",
       " 'uttakand',\n",
       " 'sentencing',\n",
       " 'slaves',\n",
       " 'vaidyaayurvedic',\n",
       " 'hindavi',\n",
       " '“”thirteen',\n",
       " 'depth',\n",
       " 'adapted',\n",
       " 'shatruwan',\n",
       " 'newracreestaophand',\n",
       " 'crippled',\n",
       " 'alphabet',\n",
       " 'numeral',\n",
       " 'wrecker',\n",
       " 'barrier',\n",
       " 'chondro',\n",
       " 'jivakarunya',\n",
       " 'borzna',\n",
       " 'emaining',\n",
       " 'grape',\n",
       " 'contacting',\n",
       " 'players',\n",
       " 'bhagatshinh',\n",
       " 'dow',\n",
       " 'thrives',\n",
       " 'harvard',\n",
       " 'visvabharati',\n",
       " 'stating',\n",
       " 'ferrying',\n",
       " 'udaipurs',\n",
       " 'pleasyre',\n",
       " 'kohima',\n",
       " 'execrable',\n",
       " 'compatibility',\n",
       " 'mazzini',\n",
       " 'kavensu',\n",
       " 'integument',\n",
       " 'proctotrypoids',\n",
       " 'explaning',\n",
       " 'eager',\n",
       " 'aah',\n",
       " 'succumbed',\n",
       " 'crew',\n",
       " 'sectorlocated',\n",
       " 'founded',\n",
       " 'bunty',\n",
       " 'objects',\n",
       " 'cesspool',\n",
       " 'munduka',\n",
       " 'anymore”',\n",
       " 'outgoing',\n",
       " 'devariya',\n",
       " 'muruganantham',\n",
       " 'suckling',\n",
       " 'processduring',\n",
       " 'congregation',\n",
       " 'intriguingly',\n",
       " 'blooms',\n",
       " 'interestrate',\n",
       " 'linters',\n",
       " 'misdiagnosis',\n",
       " 'vashikarn',\n",
       " 'shakeela',\n",
       " 'ball',\n",
       " 'domeshaped',\n",
       " 'reproductive',\n",
       " 'undervaluation',\n",
       " 'ummayad',\n",
       " 'tablets',\n",
       " 'alahabad',\n",
       " 'identifier',\n",
       " 'sadhana',\n",
       " 'gents',\n",
       " 'estimated',\n",
       " 'unaswered',\n",
       " 'musicdancedrama',\n",
       " 'mahavrata',\n",
       " 'casefrance',\n",
       " 'freezes',\n",
       " 'exploiting',\n",
       " 'kin',\n",
       " 'babus',\n",
       " 'shoe',\n",
       " 'indigence',\n",
       " 'ride',\n",
       " 'fibre',\n",
       " 'ensued',\n",
       " 'discriminate',\n",
       " 'begins',\n",
       " 'bhagavath',\n",
       " 'selfdevelopment',\n",
       " 'saha“”',\n",
       " 'iqbal',\n",
       " 'maybe',\n",
       " 'contagious',\n",
       " 'pension',\n",
       " 'cutting',\n",
       " 'narrative',\n",
       " 'strange',\n",
       " 'appoints',\n",
       " 'botchedup',\n",
       " 'metropolitan',\n",
       " 'gratuitous',\n",
       " 'compulsary',\n",
       " 'controlling',\n",
       " 'mile',\n",
       " 'gkatyal',\n",
       " 'hinterland',\n",
       " 'subal',\n",
       " 'karmasdeeds',\n",
       " 'alde',\n",
       " 'written',\n",
       " 'nothing',\n",
       " 'clippings',\n",
       " '“”dead“”and',\n",
       " 'slurry',\n",
       " 'atruaya',\n",
       " 'fearing',\n",
       " 'shinese',\n",
       " 'passionately',\n",
       " 'recaptured',\n",
       " 'dattatray',\n",
       " 'icmr',\n",
       " 'cakra',\n",
       " 'id',\n",
       " 'babri',\n",
       " 'discriminations',\n",
       " 'distant',\n",
       " 'ghonga',\n",
       " 'steady',\n",
       " 'thereafter',\n",
       " 'peps',\n",
       " 'gladden',\n",
       " 'baudha',\n",
       " 'luckies',\n",
       " 'superintendent',\n",
       " '“”dean',\n",
       " 'af',\n",
       " 'sociopoliticoeconomic',\n",
       " 'everything”',\n",
       " 'slot',\n",
       " 'havenhell',\n",
       " 'wisdoms',\n",
       " 'akbarabad',\n",
       " 'unisco',\n",
       " 'oil',\n",
       " 'sankalp',\n",
       " 'snack',\n",
       " 'remembering',\n",
       " 'lacs',\n",
       " 'moss',\n",
       " 'ashavamedh',\n",
       " 'thatuva',\n",
       " 'nowadays',\n",
       " 'coountries',\n",
       " 'aprox',\n",
       " 'fluorides',\n",
       " 'corridors',\n",
       " 'pant',\n",
       " 'susskind',\n",
       " 'reddish',\n",
       " 'onday',\n",
       " 'khrushchev',\n",
       " 'vasu',\n",
       " 'abdicating',\n",
       " 'argued',\n",
       " 'song',\n",
       " 'picturised',\n",
       " 'grafting',\n",
       " 'nida',\n",
       " 'emotionally',\n",
       " 'drumfaces',\n",
       " 'devising',\n",
       " 'agrasikandra',\n",
       " 'freshman',\n",
       " 'manipulated',\n",
       " 'gumption',\n",
       " 'caveshrine',\n",
       " 'orthodoxy',\n",
       " 'codeits',\n",
       " 'army',\n",
       " 'referenced',\n",
       " 'spam',\n",
       " 'deny',\n",
       " 'hte',\n",
       " 'chupkechupkecriminal',\n",
       " 'rioting',\n",
       " 'adam',\n",
       " 'epididymis',\n",
       " 'batters',\n",
       " 'ringverpur',\n",
       " 'negotiated',\n",
       " 'defects',\n",
       " 'hindikunj',\n",
       " 'hypercholesterolaemia',\n",
       " 'octoberwas',\n",
       " 'set',\n",
       " 'birley',\n",
       " 'tarzaajapha',\n",
       " 'sikhara',\n",
       " 'etiogenesis',\n",
       " 'gyrinus',\n",
       " 'shamser',\n",
       " 'codified',\n",
       " 'arrogant',\n",
       " 'dushan',\n",
       " 'ode',\n",
       " 'boundaries',\n",
       " 'holder',\n",
       " 'applica',\n",
       " 'shanti',\n",
       " 'bakrota',\n",
       " 'pregnant',\n",
       " 'substances',\n",
       " 'selfchosen',\n",
       " 'ratna',\n",
       " 'requesting',\n",
       " 'bets',\n",
       " 'lights”',\n",
       " 'directed',\n",
       " 'styith',\n",
       " 'rousseau',\n",
       " 'urbanachampaign',\n",
       " 'reduction',\n",
       " 'punctuated',\n",
       " 'mathematician',\n",
       " 'sheshnaaga',\n",
       " 'renewed',\n",
       " 'honey”',\n",
       " 'membersaccording',\n",
       " 'tabar',\n",
       " 'services',\n",
       " 'tatabses',\n",
       " 'primeminester',\n",
       " 'repressed',\n",
       " 'broadbased',\n",
       " 'publicised',\n",
       " 'passengers',\n",
       " 'jyanendar',\n",
       " 'shines',\n",
       " 'jr',\n",
       " 'consternation',\n",
       " 'clermontferrand',\n",
       " 'rehmaan',\n",
       " 'maganbhai',\n",
       " 'anudaat',\n",
       " 'sixtyfive',\n",
       " 'undermining',\n",
       " 'senility',\n",
       " 'blotches',\n",
       " 'soje',\n",
       " 'busyness',\n",
       " 'bellies',\n",
       " 'wishes',\n",
       " 'emprire',\n",
       " 'terrorismcomplsory',\n",
       " 'judson',\n",
       " 'staked',\n",
       " 'dipendra',\n",
       " 'subscribers',\n",
       " 'metsatkalpana',\n",
       " 'hookah',\n",
       " 'ar',\n",
       " 'ruthlessly',\n",
       " 'testified',\n",
       " 'transmitter',\n",
       " 'tocus',\n",
       " 'preschool',\n",
       " 'outcries',\n",
       " 'majoritywhen',\n",
       " 'hallways',\n",
       " 'swallowed',\n",
       " 'trapare',\n",
       " 'khaliq',\n",
       " 'rashudism',\n",
       " 'sudama',\n",
       " 'befallen',\n",
       " 'corbel',\n",
       " 'joshua',\n",
       " 'aryabhatta',\n",
       " 'dangling',\n",
       " 'campaigningvoters',\n",
       " 'tapping',\n",
       " 'largehearted',\n",
       " 'partingsong',\n",
       " 'uno',\n",
       " 'canon',\n",
       " 'nadividhadhari',\n",
       " 'francisco',\n",
       " 'staid',\n",
       " 'distracts',\n",
       " 'lagaan',\n",
       " 'usmaan',\n",
       " 'atand',\n",
       " 'katka',\n",
       " 'realization',\n",
       " 'pathogens',\n",
       " 'lakshagurhs',\n",
       " 'hall',\n",
       " '“”no',\n",
       " 'adjustments',\n",
       " 'nnactor',\n",
       " 'chiselled',\n",
       " 'sooner',\n",
       " 'singhal',\n",
       " 'banerli',\n",
       " 'windpollinated',\n",
       " 'jagirdari',\n",
       " 'unpoisoned',\n",
       " 'kp',\n",
       " 'work”',\n",
       " 'moslem',\n",
       " 'deterioration',\n",
       " 'cue',\n",
       " 'asymmetry',\n",
       " 'employ',\n",
       " 'prophesies',\n",
       " 'leaks',\n",
       " 'entitle',\n",
       " 'basrelief',\n",
       " 'onthemake',\n",
       " 'sahitya',\n",
       " 'delhis',\n",
       " 'sunderbans',\n",
       " 'wellbeing',\n",
       " 'gurus',\n",
       " 'seabirds',\n",
       " 'airlines',\n",
       " 'parents',\n",
       " 'sholay',\n",
       " 'asymmetric',\n",
       " 'sukanasika',\n",
       " 'lexus',\n",
       " 'withholds',\n",
       " 'stupidity',\n",
       " 'stagemanaged',\n",
       " 'bonn',\n",
       " 'reward',\n",
       " 'signing',\n",
       " 'machine',\n",
       " 'kitabaljabarvalmukabala',\n",
       " 'frequency',\n",
       " 'administered',\n",
       " 'verdicts',\n",
       " 'adhyatma',\n",
       " 'dragon',\n",
       " 'shah',\n",
       " 'secretary',\n",
       " 'blankets',\n",
       " 'monozygotic',\n",
       " 'attentive',\n",
       " 'dump',\n",
       " 'kusmi',\n",
       " 'slideshow',\n",
       " 'orthography',\n",
       " 'companionthe',\n",
       " 'powerpoint',\n",
       " 'europian',\n",
       " 'exprisoners',\n",
       " 'kneels',\n",
       " 'leg',\n",
       " 'rabbis',\n",
       " 'regulation',\n",
       " 'systemonline',\n",
       " 'reporter',\n",
       " 'pellucid',\n",
       " 'rheumatism',\n",
       " 'sucqessive',\n",
       " 'glitteringblue',\n",
       " 'kottukkal',\n",
       " 'childhood',\n",
       " 'jayshankar',\n",
       " 'operative',\n",
       " 'reigning',\n",
       " 'sections',\n",
       " 'capacious',\n",
       " 'whatan',\n",
       " 'shape',\n",
       " 'spoanjiosam',\n",
       " 'kochler',\n",
       " 'megapixel',\n",
       " 'formalities',\n",
       " 'serps',\n",
       " 'annum',\n",
       " 'viraah',\n",
       " 'satlaj',\n",
       " 'sorrowful',\n",
       " 'multifamous',\n",
       " 'waterfall',\n",
       " 'rock',\n",
       " 'banas',\n",
       " 'lossdraw',\n",
       " 'japans',\n",
       " 'purnnirman“”',\n",
       " 'm',\n",
       " 'runner',\n",
       " 'egocentric',\n",
       " 'briefing',\n",
       " 'chandrasekhar',\n",
       " 'phillipins',\n",
       " 'contamination',\n",
       " 'gandeev',\n",
       " 'nagpash',\n",
       " 'equipments',\n",
       " 'ramanand',\n",
       " 'cenyre',\n",
       " 'saharanpur',\n",
       " 'haddha',\n",
       " 'leans',\n",
       " 'sharavanan',\n",
       " 'accredited',\n",
       " 'breach',\n",
       " 'madurai',\n",
       " 'attract',\n",
       " 'weasel',\n",
       " 'dwan',\n",
       " 'programmer',\n",
       " 'muscle',\n",
       " 'served',\n",
       " 'protaliban',\n",
       " 'award',\n",
       " 'kailasanatha',\n",
       " 'tanks',\n",
       " 'explode',\n",
       " 'suchna',\n",
       " 'application',\n",
       " 'archly',\n",
       " 'nominations',\n",
       " 'budikote',\n",
       " 'karnakutas',\n",
       " 'wetlandsthe',\n",
       " 'leningrad',\n",
       " 'gitaadvice',\n",
       " 'unambiguously',\n",
       " 'fischer“”',\n",
       " 'omkar',\n",
       " 'surmounted',\n",
       " 'scarcely',\n",
       " 'worthy',\n",
       " 'initialised',\n",
       " 'murtaroop',\n",
       " 'plunket',\n",
       " 'lioncity',\n",
       " 'unerstan',\n",
       " 'factually',\n",
       " 'populism',\n",
       " 'quicker',\n",
       " 'desser',\n",
       " 'lamy',\n",
       " 'strathclyde',\n",
       " 'naples',\n",
       " 'flapping',\n",
       " 'creamy',\n",
       " 'proliferation',\n",
       " 'athletes',\n",
       " 'shaken',\n",
       " 'hahaal',\n",
       " 'allege',\n",
       " 'demonstration',\n",
       " 'jeopardise',\n",
       " 'telecated',\n",
       " 'thepala',\n",
       " 'excelled',\n",
       " 'worthiness',\n",
       " 'foukal',\n",
       " 'singlestorey',\n",
       " 'wife',\n",
       " 'obsolescence',\n",
       " 'scheduled',\n",
       " 'advisor',\n",
       " 'baseball',\n",
       " 'vidyasankara',\n",
       " 'gaihat',\n",
       " 'gross',\n",
       " 'numerals',\n",
       " 'et',\n",
       " 'modification',\n",
       " 'spectator',\n",
       " 'khurasa',\n",
       " 'panchappa',\n",
       " 'kavya',\n",
       " 'exclaims',\n",
       " 'haze',\n",
       " 'drharivamsha',\n",
       " 'insted',\n",
       " 'electors',\n",
       " 'chetana',\n",
       " 'kufa',\n",
       " 'cowdung',\n",
       " 'boondi',\n",
       " 'sqkm',\n",
       " 'stagger',\n",
       " 'waiting',\n",
       " 'dresses',\n",
       " 'globalisationregime',\n",
       " 'peeling',\n",
       " 'mz',\n",
       " 'ecstatic',\n",
       " 'moreover',\n",
       " 'blindly',\n",
       " 'sample',\n",
       " 'puppeteer',\n",
       " 'troubled',\n",
       " 'stretching',\n",
       " 'academys',\n",
       " 'dadamashai',\n",
       " 'scotland',\n",
       " 'forefathers',\n",
       " 'dhratrashtra',\n",
       " 'mindnumbing',\n",
       " 'condoleeza',\n",
       " 'karikala',\n",
       " 'versed',\n",
       " 'groupism',\n",
       " 'bowling',\n",
       " 'liberia',\n",
       " 'reeta',\n",
       " 'kai',\n",
       " 'aborigines',\n",
       " 'shrivastav',\n",
       " 'cyrus',\n",
       " 'complied',\n",
       " 'dharmaraja',\n",
       " 'anal',\n",
       " 'cutt',\n",
       " 'inaugural',\n",
       " 'vijaynagar',\n",
       " 'traverse',\n",
       " 'castewhich',\n",
       " 'tice',\n",
       " 'treeso',\n",
       " 'nba',\n",
       " 'nightmare',\n",
       " 'forthwith',\n",
       " 'kalaikazhanjiyam',\n",
       " 'subbalakshmi',\n",
       " 'victimless',\n",
       " 'punk',\n",
       " 'teeka',\n",
       " 'duchy',\n",
       " 'coarser',\n",
       " 'wht',\n",
       " 'noball',\n",
       " 'kund',\n",
       " 'mahendranagarbutvalhatouda',\n",
       " 'channel',\n",
       " 'upstairs',\n",
       " 'eveiything',\n",
       " 'sisu',\n",
       " 'prataparudra',\n",
       " 'diana',\n",
       " 'prema',\n",
       " 'kakori',\n",
       " 'singled',\n",
       " 'retinopathy',\n",
       " 'ramadhin',\n",
       " 'fraternal',\n",
       " 'hatched',\n",
       " 'vermas',\n",
       " 'pigmertation',\n",
       " 'invitation',\n",
       " 'bikanergovt',\n",
       " 'complainant',\n",
       " 'ulko',\n",
       " 'steelmaking',\n",
       " 'samwat',\n",
       " 'eighties',\n",
       " 'gandhineeds',\n",
       " 'parasitic',\n",
       " 'nationallevel',\n",
       " 'highhanded',\n",
       " 'sankh',\n",
       " 'peoplemany',\n",
       " 'muhamedsallahu',\n",
       " 'hurl',\n",
       " 'embarked',\n",
       " 'administrative',\n",
       " 'bends',\n",
       " 'fonts',\n",
       " 'ganj',\n",
       " 'democracy',\n",
       " 'multiscale',\n",
       " 'authorise',\n",
       " 'jodhpurjaipurjaisalmer',\n",
       " 'lefttoright',\n",
       " 'amalasila',\n",
       " 'dont',\n",
       " 'diliepnce',\n",
       " 'sourceless',\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eng_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52937"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'आघ्ढ्',\n",
       " 'चेट्टियार',\n",
       " 'सुवेदनशीलता',\n",
       " 'आयात्lत',\n",
       " 'टेक्सटाइल',\n",
       " 'ऑनलाइन',\n",
       " 'कैंटनों',\n",
       " 'सुंदरवन',\n",
       " 'गईकंपनी',\n",
       " 'विचार”',\n",
       " 'पायेंगे',\n",
       " 'बौडा',\n",
       " 'ईएससी',\n",
       " 'दे',\n",
       " 'पदों',\n",
       " 'हैंअंतराल',\n",
       " 'परिवादों',\n",
       " 'अब्बा',\n",
       " 'कार्यकुशल',\n",
       " 'समसऋऊण्श्छ्ष्त',\n",
       " 'चालpassive',\n",
       " '\\u200eबातें',\n",
       " 'फ्लोरेंस',\n",
       " 'फोड़ते',\n",
       " 'संजोये',\n",
       " 'नर्सरी',\n",
       " 'मॉड़र्न',\n",
       " 'प्रतिपिंड',\n",
       " 'चिंतनीय',\n",
       " 'हैंमैलारा',\n",
       " 'दर्जनों',\n",
       " 'चऋदह',\n",
       " 'अग़्न्याशय',\n",
       " 'रिवर',\n",
       " 'बच्चों',\n",
       " 'दियावे',\n",
       " 'गाँवघर',\n",
       " 'डालें',\n",
       " 'सोया',\n",
       " 'प्रयतऋऊण्श्छ्ष्न',\n",
       " 'अंतर्मुखी',\n",
       " 'वार्डन',\n",
       " 'हैवलाक',\n",
       " 'गुस्सा',\n",
       " 'ओपीनियन',\n",
       " 'मुहैया',\n",
       " 'प्रेसीड़ेंसी',\n",
       " 'चिले',\n",
       " 'ईश्वर।',\n",
       " 'तदनन्तर',\n",
       " 'फूटता',\n",
       " 'बलोचिस्तान',\n",
       " 'हूंमैं',\n",
       " 'ह्यन्याय',\n",
       " 'अनुसमर्थन',\n",
       " 'प्रदर्शनियां',\n",
       " 'मेसोपोटामिया',\n",
       " 'कॉडलिवर',\n",
       " 'idkae',\n",
       " 'समय।',\n",
       " 'चारती',\n",
       " 'षण्मत',\n",
       " 'मेर',\n",
       " 'गलफाड़े',\n",
       " 'बीच।',\n",
       " 'करनाल',\n",
       " 'गुर्दों',\n",
       " 'बाली',\n",
       " 'ईरानियों',\n",
       " 'बांधी',\n",
       " 'haiking',\n",
       " 'हठधर्मी',\n",
       " 'सब्सक्राईब्ड',\n",
       " 'ग्रीष्मकालीन',\n",
       " 'भगोड़ें',\n",
       " 'बीस',\n",
       " 'इलाजो',\n",
       " 'gate',\n",
       " 'zबल्कि',\n",
       " 'रखेगा',\n",
       " '“',\n",
       " 'पिछड़े',\n",
       " 'ºघूम',\n",
       " 'नदीजीवन',\n",
       " 'चैम्पियनशिप',\n",
       " 'परछाई',\n",
       " 'पाणिनि',\n",
       " 'india।',\n",
       " 'मध्यदेश',\n",
       " 'पत्रिका',\n",
       " 'दरोगों',\n",
       " 'मांकड',\n",
       " 'बींध',\n",
       " 'बढेचढेकर',\n",
       " 'घडऋयिआल',\n",
       " 'कूदना',\n",
       " 'फर्रुखाबाद',\n",
       " 'प्रायद्धीप',\n",
       " 'काजी',\n",
       " 'नमन',\n",
       " 'सूबेदार',\n",
       " 'पीनल',\n",
       " 'नकंशे',\n",
       " 'रसोइयों',\n",
       " 'छुरा',\n",
       " 'धराशायी',\n",
       " 'खाँसी',\n",
       " 'उपयॊगकर्तॊं',\n",
       " 'सनसीखेज',\n",
       " 'लक्ष्यद्वीप',\n",
       " 'मेंभी',\n",
       " 'imala',\n",
       " 'उभारों',\n",
       " 'बैरी',\n",
       " 'हैउपनगर',\n",
       " 'प्रोग्रेस',\n",
       " 'हैडाzयबिटिक',\n",
       " 'ecosystems',\n",
       " 'आदिमजातियों',\n",
       " 'पुनःस्थापन',\n",
       " 'पढ़ेलिखे',\n",
       " 'कुंटे',\n",
       " 'इंजरीज़',\n",
       " 'दियाजब',\n",
       " 'bhopal',\n",
       " 'वेस्टold',\n",
       " 'इयरियस',\n",
       " 'अध्यायी',\n",
       " 'ख़ाका',\n",
       " 'सिरमौरी',\n",
       " 'हैजंगली',\n",
       " 'चॉकलेट',\n",
       " 'janasabaa',\n",
       " 'गुम्मटे',\n",
       " 'ताज',\n",
       " 'सीआईडी',\n",
       " 'बद्ध',\n",
       " 'गर्ली',\n",
       " 'बंदीप',\n",
       " 'ठेला',\n",
       " 'ब्राउसर',\n",
       " 'हैंतब',\n",
       " 'स्टब्ब्लफील्ड',\n",
       " 'सोशलिस्ट',\n",
       " 'मुखर',\n",
       " 'प्रसाधन',\n",
       " 'रहस्यवादियों',\n",
       " '\\u200eबना',\n",
       " 'घोषणपत्र',\n",
       " 'केंद्रबिंदु',\n",
       " 'बैकाल',\n",
       " 'गांठ',\n",
       " 'इब्रानी',\n",
       " 'संलयन',\n",
       " 'तेराऊची',\n",
       " 'मैकेनिकल',\n",
       " 'चलाऊ',\n",
       " 'अंगरक्षक',\n",
       " 'अन्तान्वाद',\n",
       " 'अल्प',\n",
       " 'मिलीं',\n",
       " 'पिन्',\n",
       " 'मैथिली',\n",
       " 'सऋरा',\n",
       " 'अर्निको',\n",
       " 'बन्धुओं',\n",
       " 'अंशों',\n",
       " 'mऔर',\n",
       " 'चाह',\n",
       " 'दिवंगत',\n",
       " 'बोद्धा',\n",
       " 'संसदों',\n",
       " 'तत्वज्ञान',\n",
       " 'डिप्लोमैटिक',\n",
       " 'अर्पित',\n",
       " 'हैंनर',\n",
       " 'अधिनायकवाद',\n",
       " 'ड्रीम्स',\n",
       " 'जुलाहे',\n",
       " 'लटकाते',\n",
       " 'रूहर',\n",
       " 'हैमार्ग',\n",
       " 'ह्यण्mथ्',\n",
       " 'लाजान्या',\n",
       " 'सर्वसमऋऊण्श्छ्ष्मति',\n",
       " 'पृष्ठ',\n",
       " 'उपोष्णकटिबन्धीय',\n",
       " 'एकसत्तावादी',\n",
       " 'पत्रकार',\n",
       " 'सड़े',\n",
       " 'दष्टिकोंण',\n",
       " 'बजाता',\n",
       " 'कलात्मक',\n",
       " 'भ्रमकारी',\n",
       " '‘नौका',\n",
       " 'मकबरा।',\n",
       " 'पुनर्भरण',\n",
       " 'genitalispearly',\n",
       " 'अकऋऊण्श्छ्ष्सर',\n",
       " 'प्राणघाती',\n",
       " 'गोवर्धन',\n",
       " 'दक्षिणपूरब',\n",
       " 'काद्मबरी',\n",
       " 'जर्सी',\n",
       " 'शिव',\n",
       " 'फयाज',\n",
       " 'मखरला',\n",
       " 'शाहिया',\n",
       " 'gpको',\n",
       " 'वैदुष्य',\n",
       " 'तुर्कों',\n",
       " 'दोषमुक्त',\n",
       " 'ढफ',\n",
       " 'बुद्धिजीवियों',\n",
       " 'मोहरबंद',\n",
       " 'होमो',\n",
       " 'आसक्ति',\n",
       " 'हाब्स',\n",
       " 'ढीलेपन',\n",
       " 'लेव',\n",
       " 'आयेगा।',\n",
       " 'बुनाईकढ़ाई',\n",
       " 'श्रेणीभक्तिकाल',\n",
       " 'जयतु',\n",
       " 'सहृदयता',\n",
       " 'राष्ट्रसेवापर्व',\n",
       " 'गैरजिमेदार',\n",
       " 'कृष्णन',\n",
       " 'सूक्ष्मतर',\n",
       " 'सहस्र',\n",
       " 'देगीं',\n",
       " 'नियामक',\n",
       " 'स्मृतियां',\n",
       " 'नकारते',\n",
       " 'काठियावाड़',\n",
       " 'बढाएँगे',\n",
       " 'निराशी',\n",
       " 'कहोगी',\n",
       " 'ब्रह्मज्ञान',\n",
       " 'विज्ञानिक',\n",
       " 'निषऋऊण्श्छ्ष्पक्ष',\n",
       " 'फैलते',\n",
       " 'avcस्तेरेओ',\n",
       " 'रोलर',\n",
       " 'पॉलीअसंतृप्त',\n",
       " 'एकसाथ',\n",
       " 'शालाओं',\n",
       " 'ऐडऋई',\n",
       " 'फ़िल्मों',\n",
       " 'ईंधनों',\n",
       " 'पहरेदारों',\n",
       " 'टकराएगी',\n",
       " 'अफ़गानिस्तान',\n",
       " 'ढंककर',\n",
       " 'घ्यान',\n",
       " 'पैरोडी',\n",
       " 'सामरिक',\n",
       " 'सोशल',\n",
       " 'धूसरपन',\n",
       " 'मेढ़े',\n",
       " 'उपदेवताओं',\n",
       " 'चलेगी',\n",
       " 'नित्यप्रति',\n",
       " 'पुराण',\n",
       " 'ली',\n",
       " 'मादागास्कर',\n",
       " 'ह्रयूम',\n",
       " 'बगिया',\n",
       " 'चैरिटी',\n",
       " 'रंगरुपादि',\n",
       " 'मीड',\n",
       " '\\u200eतिलावत',\n",
       " 'कुप्पम',\n",
       " 'जौहरियों',\n",
       " 'मिला',\n",
       " 'स्नेहक',\n",
       " 'पट्टें',\n",
       " 'नॉइस',\n",
       " 'सहानुभूतियों',\n",
       " 'बिल्डिंग',\n",
       " 'शक्तिहीन',\n",
       " 'कॉर्पोरेशन',\n",
       " 'पुनर्जागरण',\n",
       " 'देक्र्यप्तिंग',\n",
       " 'रमानी',\n",
       " 'परिस्थितियां',\n",
       " 'जमीअत',\n",
       " 'स्वास्थ्',\n",
       " 'चिली',\n",
       " 'संतुलन',\n",
       " 'व्यथा',\n",
       " 'भुरभुरा',\n",
       " 'निर्णय',\n",
       " 'चढ़कर',\n",
       " 'लेनयार्ड़',\n",
       " 'निरस्ता',\n",
       " 'करीन',\n",
       " 'ऊबाऊ',\n",
       " 'गौओं',\n",
       " 'ख़ानाबदोश',\n",
       " 'सीरीज',\n",
       " 'वरणात्मक',\n",
       " 'gaaova',\n",
       " 'खूबसूरती',\n",
       " 'अवशेष',\n",
       " 'हैंभाजपा',\n",
       " 'खंभे',\n",
       " 'पद्धतीयों',\n",
       " 'संकल्पिता',\n",
       " 'देखिए',\n",
       " 'आआआआअह्ह्ह्ह्ह्ह्ह।',\n",
       " 'सिलंबम',\n",
       " 'मिलेंभाष्',\n",
       " 'मानदंड़',\n",
       " 'अपरिवर्तनीय',\n",
       " 'तिलकोर',\n",
       " 'तबादलं',\n",
       " 'घबड़ा',\n",
       " 'definition',\n",
       " 'अतंरालों',\n",
       " 'नारदपुराण',\n",
       " 'स्वास्थ',\n",
       " 'निकला',\n",
       " 'अंलकरणों',\n",
       " 'टैवर्नियर',\n",
       " 'बंगाल',\n",
       " 'एकाश्मक',\n",
       " 'वायुजनित',\n",
       " 'उदात्तभाव',\n",
       " 'निर्माणसमाप्ति',\n",
       " 'रखा',\n",
       " 'बेचकर',\n",
       " 'जोडते',\n",
       " 'लगवाते',\n",
       " 'अलवर',\n",
       " 'रविवार',\n",
       " 'कलाकारों',\n",
       " 'सोची',\n",
       " 'कहनी',\n",
       " 'हथकरघे',\n",
       " 'हिमनदों',\n",
       " 'बरसाता',\n",
       " 'जन्में',\n",
       " 'हमरी',\n",
       " 'नाराजी',\n",
       " 'असफ़लता',\n",
       " 'चौरासी',\n",
       " 'संविधानविरुद्ध',\n",
       " 'हालस्टार्म',\n",
       " 'शिल्पकला',\n",
       " 'वसूलने',\n",
       " 'यामिनी',\n",
       " 'डायावीटीज़',\n",
       " 'कसक',\n",
       " 'वाचान्तरराजभाषा',\n",
       " 'बैंकिंग',\n",
       " 'मुज्ह्से',\n",
       " 'कसरत',\n",
       " 'जनाना',\n",
       " 'अम',\n",
       " 'अनुमानत',\n",
       " 'हुईसन्',\n",
       " 'प्रवेशी',\n",
       " 'निवेशकखासकर',\n",
       " 'pearson',\n",
       " 'मनूष्यो',\n",
       " 'जिंजरब्रेड',\n",
       " 'राषट्रपति',\n",
       " 'प्रतिवेदन',\n",
       " 'आइएमयू',\n",
       " 'आबिद',\n",
       " 'सचित्र',\n",
       " 'जाएँगी',\n",
       " 'टिम्बिट्टू',\n",
       " 'आ',\n",
       " 'पौधो',\n",
       " 'बैठी',\n",
       " 'औरा',\n",
       " 'फतेह',\n",
       " 'गाड़ी',\n",
       " 'रेगिस्तानी',\n",
       " 'भूमिगत',\n",
       " 'मलेरिआ',\n",
       " 'पहली',\n",
       " 'बहुतम',\n",
       " 'विवेचनी',\n",
       " 'नौबत',\n",
       " 'गीतपुत्र',\n",
       " 'रब्बी',\n",
       " 'समापत',\n",
       " 'पेरोक्साइस्टायल',\n",
       " 'रसायन',\n",
       " 'मुंडन',\n",
       " 'बेयरफ़ुट',\n",
       " 'चित्रकरी',\n",
       " 'भागेदारी',\n",
       " 'दीवारों',\n",
       " 'अलकनन्दा',\n",
       " 'घेराव',\n",
       " 'प्रतीचत',\n",
       " 'अबाध',\n",
       " 'चाकी',\n",
       " 'भमूल्य',\n",
       " 'इंजीनियरों',\n",
       " 'प्रांतीयता',\n",
       " 'कक्षासन',\n",
       " 'खंडकाव्य',\n",
       " 'गंद',\n",
       " 'हैबॉन',\n",
       " 'सन्हाई',\n",
       " 'चाँद',\n",
       " 'टेक्निशियनों',\n",
       " 'वांगमय',\n",
       " 'गुणवत्त्ता',\n",
       " 'भी\\x14',\n",
       " 'zप्रांतीय',\n",
       " 'खुँभी',\n",
       " 'सिकुड़ता',\n",
       " 'वाउअल्स',\n",
       " 'नर्मी',\n",
       " 'पाठ्यक्रम',\n",
       " 'प्रतिषेध',\n",
       " 'आचरणों',\n",
       " 'फार्म',\n",
       " 'लॅटरी',\n",
       " 'झाँक',\n",
       " 'गयीअसऋऊण्श्छ्ष्साजी',\n",
       " 'जोह',\n",
       " 'अप्रैलः',\n",
       " 'लोकमत',\n",
       " 'देवकी',\n",
       " 'pamtirt',\n",
       " 'नाली',\n",
       " 'सन्तुष्ट',\n",
       " 'टीनैंसी',\n",
       " 'चुटकीभर',\n",
       " 'जानबूझकर',\n",
       " '\\u200eज्ञानवान',\n",
       " 'अचरच',\n",
       " 'मधुमेह',\n",
       " 'जलधारा',\n",
       " 'यौनांग',\n",
       " 'रिट',\n",
       " 'सामान्यजन',\n",
       " 'परिपूर्णता',\n",
       " 'नक्काशियां',\n",
       " 'कोशिकाएं',\n",
       " 'तिस',\n",
       " 'सुपरवाइजरौ',\n",
       " 'भोगों',\n",
       " 'शाखाओं',\n",
       " 'चुनोतियों',\n",
       " 'लगती',\n",
       " 'चाहिएवैधानिक',\n",
       " 'चबाए',\n",
       " 'भक्तिभाव',\n",
       " 'प्रदूषणमुक्त',\n",
       " 'व्यापारसम्बन्धी',\n",
       " 'पेंशन',\n",
       " 'बड़बड़ाते',\n",
       " 'दंगाई',\n",
       " 'जवाहरात',\n",
       " 'अकेली',\n",
       " 'अपास्त',\n",
       " 'मेंक्रमश',\n",
       " 'लज्जावश',\n",
       " 'छिपाते',\n",
       " 'हरि',\n",
       " 'मांस',\n",
       " 'अक्सर',\n",
       " 'अनुलंब',\n",
       " 'थीं।',\n",
       " 'इक्वॉलिटी',\n",
       " 'बनाईउन्होंने',\n",
       " 'गंगायमुना',\n",
       " 'ग़रीबों',\n",
       " 'बनवानें',\n",
       " 'ईमारतों',\n",
       " 'dixanai',\n",
       " 'स्पेनिश',\n",
       " 'शिलींग',\n",
       " 'ड़िपो',\n",
       " 'यज्ञोपवीत',\n",
       " 'अपरिचिता',\n",
       " 'मित्तल',\n",
       " 'अभिरूचि',\n",
       " 'झलकती',\n",
       " 'हाटेश्वरी',\n",
       " 'भीtमोबाइल',\n",
       " 'iya',\n",
       " 'बथारी',\n",
       " 'स्टोरेज',\n",
       " 'मंदरीन',\n",
       " 'बेचैन',\n",
       " 'मैपमेकर',\n",
       " 'खजूर',\n",
       " 'मुसलमान।',\n",
       " 'डेली',\n",
       " 'भरो”',\n",
       " 'अश्वों',\n",
       " 'व्याख्यात्मक',\n",
       " 'accomplishing',\n",
       " 'bunty',\n",
       " 'आधुनिकीकरण',\n",
       " 'दरनीति',\n",
       " 'पैट्रोलपंप',\n",
       " 'वासनाओं',\n",
       " 'सिंहली',\n",
       " 'नथुनों',\n",
       " 'प्रबाव',\n",
       " 'अधिवेशनों',\n",
       " 'आइएएस',\n",
       " 'केवड़ा',\n",
       " 'कोषाणु',\n",
       " 'ज़रुरत',\n",
       " 'तलवार',\n",
       " 'कर्णफूल',\n",
       " 'नॉन',\n",
       " 'पल्लवकाल',\n",
       " 'शिवलीलापरक',\n",
       " 'ball',\n",
       " 'अभिनेत्रियों',\n",
       " 'हिकमतों',\n",
       " 'स्पषट',\n",
       " 'महत्वपूर्न',\n",
       " 'कथ्य',\n",
       " 'ज़कात',\n",
       " 'ध्वस्थ',\n",
       " 'प्लगों',\n",
       " 'पिटी',\n",
       " 'बेकन',\n",
       " 'चूड़ामणि',\n",
       " 'अदालती',\n",
       " 'रहेगा',\n",
       " 'नेट',\n",
       " 'आपवासिय',\n",
       " 'बनानी',\n",
       " 'मोडल',\n",
       " 'फारसियों',\n",
       " 'नदी।',\n",
       " 'ची',\n",
       " 'वल्लभाचार्य',\n",
       " 'बेचा',\n",
       " 'वाग्वैदग्ध्यपूर्ण',\n",
       " 'अशऋऊण्श्छ्ष्वनालाकार',\n",
       " 'देशभक़्तों',\n",
       " 'शून्यता',\n",
       " 'हुछ',\n",
       " 'ह्दय',\n",
       " 'मॉटिफों',\n",
       " 'लैटिन',\n",
       " 'हिमशृंखलायें',\n",
       " 'एन्चैन्ट्रेस',\n",
       " 'प्रतिभावान',\n",
       " 'उपयोगमे',\n",
       " 'कहलाने',\n",
       " 'पैरोडियाँ',\n",
       " 'आस्ट्रिया',\n",
       " 'पार्विक',\n",
       " 'डटीं।',\n",
       " 'कैंब्रिज',\n",
       " 'खिंचा',\n",
       " 'नुमाइंदगी',\n",
       " 'छोड़ेंगे',\n",
       " 'आंतों',\n",
       " 'हेक़्सापोडा',\n",
       " 'संग्रहपाल',\n",
       " 'ज्हेंपड़ें',\n",
       " 'इटलीसमेत',\n",
       " 'शेवी',\n",
       " 'बेड़ियां',\n",
       " 'शबाना',\n",
       " 'आत्मज्ञान',\n",
       " 'सत्कर्म',\n",
       " 'ज्ञानध्यान',\n",
       " 'स्थापक',\n",
       " 'अधिष्ठाता',\n",
       " 'लोकगीतोंखासकर',\n",
       " 'वाल्टायिक',\n",
       " 'जमी',\n",
       " 'महत्वकांक्षी',\n",
       " 'बदलूं',\n",
       " 'आइसक्रीम',\n",
       " 'वाराणसी',\n",
       " 'रिपोर्टिंग',\n",
       " 'वाल्वी',\n",
       " 'संभवत',\n",
       " 'alde',\n",
       " 'आपैत्त',\n",
       " 'एमरजेंसी',\n",
       " 'विनय',\n",
       " 'महतऋऊण्श्छ्ष्वपूर्ण',\n",
       " 'ब्रदर्स',\n",
       " 'हैमुस्लिम',\n",
       " 'बोल्डर',\n",
       " 'portसे',\n",
       " 'दिगलीपुर',\n",
       " 'zचाहिए',\n",
       " 'नवीनतम',\n",
       " 'टुड़े',\n",
       " 'industrialउत्सर्जन',\n",
       " 'indexके',\n",
       " 'id',\n",
       " 'उधारी',\n",
       " 'गंवानी',\n",
       " 'हैवह',\n",
       " 'लिच्छवियो',\n",
       " 'आलग',\n",
       " 'स्टाम्पों',\n",
       " 'ग्रुप',\n",
       " 'एगान',\n",
       " 'सक्रीय',\n",
       " 'ओरेगान',\n",
       " 'kaoisaxa',\n",
       " 'धोते',\n",
       " 'रोशन',\n",
       " 'प्रजनन',\n",
       " 'निन',\n",
       " 'केबीसी',\n",
       " 'तुनतुने',\n",
       " 'कलगी',\n",
       " 'मढ़ने',\n",
       " 'सूचियों',\n",
       " 'आर्सपास',\n",
       " 'बसें',\n",
       " 'नवागंतुक',\n",
       " 'उन्नती',\n",
       " 'स्वपुरुष',\n",
       " 'पुष्पकविमान',\n",
       " 'चाहिएl',\n",
       " 'ड्वायने',\n",
       " 'विकलानाता',\n",
       " 'रत्नागिरी',\n",
       " 'आतंक',\n",
       " 'hsaaxar',\n",
       " 'कलेवर',\n",
       " 'संपन्नता',\n",
       " 'थुथनी',\n",
       " 'शापिंग',\n",
       " '“मेरी',\n",
       " 'जीरोक्स',\n",
       " 'वोलन्टियर',\n",
       " 'हैंइसके',\n",
       " 'एंटीपर्स्परैंट',\n",
       " 'चायदानी',\n",
       " 'आफलाईन',\n",
       " 'कैजन',\n",
       " 'जागते',\n",
       " 'प्याजआकार',\n",
       " 'सारनाथ',\n",
       " 'सालों',\n",
       " 'लखनपाल',\n",
       " 'वैवर्त',\n",
       " 'मक्खदाल',\n",
       " 'गणमान्य',\n",
       " 'हाँ',\n",
       " 'भाला',\n",
       " 'हिन्दईरानी',\n",
       " 'छंटनी',\n",
       " 'तरीकों',\n",
       " 'अत्यावश्यक',\n",
       " 'बेपरदा',\n",
       " 'mauऊण्श्छ्ष्o',\n",
       " 'शुक्रिया।',\n",
       " 'सैटरनिड',\n",
       " 'प्रश्न',\n",
       " 'फ़ूँकते',\n",
       " 'म्युजिक',\n",
       " 'करीबकरीब',\n",
       " 'धात्री',\n",
       " 'army',\n",
       " 'डब्ल्यू',\n",
       " 'खडों',\n",
       " 'गेट',\n",
       " 'नानाशह',\n",
       " 'अतंरों',\n",
       " 'भक्तों',\n",
       " 'डिपार्टमेंट्स',\n",
       " 'ढोंग',\n",
       " 'बसती',\n",
       " 'सक्सोन',\n",
       " 'फ़र्क',\n",
       " 'शिपिंग',\n",
       " 'फिरदौस',\n",
       " 'सुप्रसिद्ध',\n",
       " 'जिसमं',\n",
       " 'गंजाम',\n",
       " 'कृषक',\n",
       " 'मचलती',\n",
       " 'लोगबाग',\n",
       " 'नीतिनिर्माता',\n",
       " 'अवतरित',\n",
       " 'मढ़ा',\n",
       " 'लहरमात्र',\n",
       " 'पुकाराऋषि',\n",
       " 'अन्दूलेसिया',\n",
       " 'धारणाओं',\n",
       " 'अधिष्ठित',\n",
       " 'सूँघते',\n",
       " 'निचला',\n",
       " 'परमिट',\n",
       " 'मुहिम',\n",
       " 'इमीग्रेशन',\n",
       " 'कर्य',\n",
       " 'ग्रामचुनाव',\n",
       " 'रोशनी',\n",
       " 'बारहवाँ',\n",
       " 'ज्हंसे',\n",
       " 'गन',\n",
       " 'यूनीवर्सिटी',\n",
       " 'चाहतेचाहती',\n",
       " 'इंसानी',\n",
       " 'पदावधि',\n",
       " 'दऋरान',\n",
       " 'आस्की',\n",
       " 'अस्सेस्स्मेन्ट्',\n",
       " 'पेड़ें',\n",
       " 'स्पंज',\n",
       " 'द्वारकापुरी',\n",
       " 'विद्रोह',\n",
       " 'कराया।',\n",
       " 'स्लीमन',\n",
       " 'प्रकारसे',\n",
       " 'सुलझाए',\n",
       " 'विड़ंबना',\n",
       " 'पांडव',\n",
       " 'चटगांवप्रसंग',\n",
       " 'टिकेट',\n",
       " 'जीर्णशीर्ण',\n",
       " 'क्या”',\n",
       " 'कैनरी',\n",
       " 'दुखाने',\n",
       " 'जलाधर',\n",
       " 'निर्विघ्न',\n",
       " 'जातराओं',\n",
       " 'मिटाना',\n",
       " 'बुझ',\n",
       " 'urbanachampaign',\n",
       " 'reduction',\n",
       " 'विस्मित',\n",
       " 'लेटाया',\n",
       " 'ऋसका',\n",
       " 'असंशोधित',\n",
       " 'मेष',\n",
       " 'तुंगा',\n",
       " 'वैतरणी',\n",
       " 'नेशन',\n",
       " 'सिलसिलेवार',\n",
       " 'भाष्णशैली',\n",
       " 'सींकों',\n",
       " 'ती',\n",
       " 'संस्कृति',\n",
       " 'बाधक',\n",
       " 'प्रोजेक़्टों',\n",
       " 'शिकायतें',\n",
       " 'वायुजनिक',\n",
       " 'ह्यण्छ्छ्हृ',\n",
       " 'घर्षणवाद्यों',\n",
       " 'निर्मातों',\n",
       " 'रविल्ला',\n",
       " 'दादीमाँ',\n",
       " 'तालिबान',\n",
       " 'राशियों',\n",
       " 'लिखूं',\n",
       " 'श्रेणीप्रेमचंद',\n",
       " 'पोनप्पा',\n",
       " 'इत्यादि।',\n",
       " 'आवंटित',\n",
       " 'पालियों',\n",
       " 'प्रश्नों',\n",
       " 'अध्ध्यन',\n",
       " 'रसोई',\n",
       " 'पेंटयाल',\n",
       " 'judson',\n",
       " 'हिन्दुस्थान',\n",
       " 'तारपो',\n",
       " 'दार्शनिको',\n",
       " 'हटाए',\n",
       " 'मेनहट्टन',\n",
       " 'धारावाही',\n",
       " 'राठौंड़ों',\n",
       " 'संलियतों',\n",
       " 'अफ्रीका',\n",
       " 'पंइकंत',\n",
       " 'डीडी',\n",
       " 'समाधानकारक',\n",
       " 'नियोजकों',\n",
       " 'गुगली',\n",
       " 'तांडवमूर्ति',\n",
       " 'ar',\n",
       " 'कोईकोई',\n",
       " 'वर्तनीजाँचक',\n",
       " 'अऑइऋस',\n",
       " 'धात्विक',\n",
       " 'गिना',\n",
       " 'आँखे',\n",
       " 'तऋऊण्श्छ्ष्यऋहार',\n",
       " 'विण्णघम',\n",
       " 'कोशिशें',\n",
       " 'चार्टरित',\n",
       " 'श्mऐआष्',\n",
       " 'नव्योत्तर',\n",
       " 'नलियों',\n",
       " 'दाएं',\n",
       " 'क़विता',\n",
       " 'पतित',\n",
       " 'रोहतर्कदिलऋऊण्श्छ्ष्ली',\n",
       " 'प्रतिजैविक',\n",
       " 'थादेश',\n",
       " 'टिपएक्स',\n",
       " 'बंदरों',\n",
       " 'गोलार्द्ध',\n",
       " 'स्वांग',\n",
       " 'सालसेट्टे',\n",
       " 'प्रहरी',\n",
       " 'पर्यवेक्षक',\n",
       " 'आनन्ददायक',\n",
       " 'उच्चतकनीकी',\n",
       " '\\u200eयाद',\n",
       " 'francisco',\n",
       " 'निर्धारण',\n",
       " 'पी।',\n",
       " 'बेंचमार्क',\n",
       " 'लाइफ़जैकेट',\n",
       " 'बारूद',\n",
       " 'थेलों',\n",
       " 'नियोजनों',\n",
       " 'जालोर',\n",
       " 'रिवरसाईड',\n",
       " 'जायअच्छा',\n",
       " 'चुंबकों',\n",
       " 'होराजनीतिक',\n",
       " 'डैथ',\n",
       " 'खपत',\n",
       " 'अकंतूबर',\n",
       " 'निंदा',\n",
       " 'भिऋ',\n",
       " 'लद्दाख़',\n",
       " 'मेजिस्ट्रेट्स',\n",
       " 'चाहूंगा',\n",
       " 'आदान',\n",
       " 'शैसयतें',\n",
       " 'पंखहीन',\n",
       " 'मासेक्टोमी',\n",
       " 'थीइसका',\n",
       " 'बोलीभाषाओं',\n",
       " 'नीली',\n",
       " 'ऑफर',\n",
       " 'हैअष्टभुज',\n",
       " 'उपद्रवों',\n",
       " 'ध्वंस',\n",
       " 'प्रोत्साहनों',\n",
       " 'स्पाइस',\n",
       " 'जोखिमउठाया',\n",
       " 'siberiaसे',\n",
       " 'देवाताओं',\n",
       " 'सुलझानी',\n",
       " 'नेहरूसमिति',\n",
       " 'वेर्सल्लिएस',\n",
       " 'दोषमुक़्त',\n",
       " 'आतंकवादियों',\n",
       " 'डैल',\n",
       " 'टकराने',\n",
       " 'शराबा',\n",
       " 'bonn',\n",
       " 'किसीप्रकार',\n",
       " 'प्रक्षेपवक्र',\n",
       " 'machine',\n",
       " 'मरकज',\n",
       " 'समावेशी',\n",
       " 'एम्',\n",
       " 'ज़्यां',\n",
       " 'स्ट्रोक',\n",
       " 'शुद्धता',\n",
       " 'फ्लाप',\n",
       " 'आईसीयू',\n",
       " 'संगति',\n",
       " 'वसऋऊण्श्छ्ष्तुतया',\n",
       " 'दीपेंद्र',\n",
       " 'मिठाइयाँ',\n",
       " 'योधा',\n",
       " 'होगमैन',\n",
       " 'पडऋता',\n",
       " 'कृतार्थ',\n",
       " 'शोरगुल',\n",
       " 'शयन',\n",
       " 'मुसीबतें',\n",
       " 'हैंअन्य',\n",
       " 'आत्मपरक',\n",
       " 'ईन्ङोर्मटिओन्',\n",
       " 'शल्यचिकित्सा',\n",
       " 'योग्यता',\n",
       " 'leg',\n",
       " 'तांगे',\n",
       " 'धर्मवार्ताओं',\n",
       " 'जाम',\n",
       " 'भट्ठी',\n",
       " 'धैर्यशील',\n",
       " 'reporter',\n",
       " 'जादूटोना',\n",
       " 'पुक्सी',\n",
       " 'इकहरी',\n",
       " 'सुंदरलाल',\n",
       " 'गुच्छेवाली',\n",
       " 'मिथ्या',\n",
       " 'आभा',\n",
       " 'मेंउपबंध',\n",
       " 'हुआतब',\n",
       " 'सरफिरा',\n",
       " 'उपस्थिती',\n",
       " 'प्रवर्तिका',\n",
       " 'जंगलं',\n",
       " 'संपतिधारकों',\n",
       " 'इन्द्रियबोध',\n",
       " 'झिल्लियों',\n",
       " 'जेटी',\n",
       " 'सिलाईदह',\n",
       " 'अतृप्त',\n",
       " 'स्वामियों',\n",
       " 'लेटे',\n",
       " 'दबाता',\n",
       " 'पांचवां',\n",
       " 'चट्',\n",
       " 'प्रभावपूर्ण',\n",
       " 'उड़ेगा',\n",
       " 'लिखनापढ़ना',\n",
       " 'चॉइस”।',\n",
       " 'मार्टिन',\n",
       " 'शीतलन',\n",
       " 'मैंने',\n",
       " 'बहुगुणन',\n",
       " 'युवराज',\n",
       " 'रिकॉर्ड़ों',\n",
       " 'अल्पसंयकों',\n",
       " 'चूसता',\n",
       " 'वर्णमाला',\n",
       " 'm',\n",
       " 'ताराचंद',\n",
       " 'जन्मलग़्न',\n",
       " 'अरूप',\n",
       " 'लगकर',\n",
       " 'नैपकिन',\n",
       " 'सांडों',\n",
       " 'दायीं',\n",
       " 'ताजगी',\n",
       " 'ब्रुक',\n",
       " 'संयोगवियाग',\n",
       " 'विशेषतौर',\n",
       " 'अंधेरा',\n",
       " 'डीजी',\n",
       " 'रहवासी',\n",
       " 'पड़ीडोरोथी',\n",
       " 'लाउडस्पीकर',\n",
       " 'सहलाकर',\n",
       " 'बीमारियां',\n",
       " 'थासेल',\n",
       " 'पद्यात्मक',\n",
       " 'वादकार्य',\n",
       " 'एग्ज़ामिनेशंस',\n",
       " 'काटती',\n",
       " 'झंझा',\n",
       " 'समितितो',\n",
       " 'बहुतबहुत',\n",
       " 'जमैका',\n",
       " 'मौते',\n",
       " 'स्पिरिट',\n",
       " 'सापेक्षत',\n",
       " 'करवाऊँगा।”',\n",
       " 'सांख्यिकी',\n",
       " 'रई',\n",
       " 'लीड़्स',\n",
       " 'अनुरुप',\n",
       " 'उतारे',\n",
       " 'प्रैस',\n",
       " 'जेपीदत्ता',\n",
       " 'कतार',\n",
       " 'application',\n",
       " 'समझोतों',\n",
       " 'तात्विक',\n",
       " 'दानशील',\n",
       " 'पंद्रह',\n",
       " 'नीतियॉ',\n",
       " 'इन्टरनेट',\n",
       " 'सनधाने',\n",
       " 'दुबकाकर',\n",
       " 'जड़',\n",
       " 'रहन',\n",
       " 'मिशनरीज',\n",
       " 'बेच',\n",
       " 'yउर',\n",
       " 'महासचिव',\n",
       " 'तापमानों',\n",
       " 'होनहार',\n",
       " 'वार्ड़रोब',\n",
       " 'निधियों',\n",
       " 'प्रतिकूलसे',\n",
       " 'सरमद',\n",
       " 'संस्करण',\n",
       " 'तेजस्विता',\n",
       " 'जिंदगीयाँ',\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hindi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>islam is word from arabic and it full word is salamaits definition peace surrender</td>\n",
       "      <td>START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका मूल शब्द सल्लमा है जिस की दो परिभाषाएं हैं शान्ति आत्मसमर्पण। _END</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118633</th>\n",
       "      <td>ted</td>\n",
       "      <td>everything is reliant on these computers working</td>\n",
       "      <td>START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113495</th>\n",
       "      <td>tides</td>\n",
       "      <td>parliament does not control the government</td>\n",
       "      <td>START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>tides</td>\n",
       "      <td>race equality new laws</td>\n",
       "      <td>START_ नये कानून नस्ली समानता _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111804</th>\n",
       "      <td>tides</td>\n",
       "      <td>the provision would not affect the power of parliament to make laws in respect of income from professions etc lrb article rrb</td>\n",
       "      <td>START_ व्यवसायों आदि से होने वाली आय के बारे में विधि बनाने की संसद की शक्ति पर उपबंध का प्रभाव नहीं पड़ेगा अनुच्छेद _END</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                                                                                               english_sentence                                                                                                             hindi_sentence  length_eng_sentence  length_hin_sentence\n",
       "25520   indic2012  islam is word from arabic and it full word is salamaits definition peace surrender                                             START_ इस्लाम शब्द अरबी भाषा का शब्द है जिसका मूल शब्द सल्लमा है जिस की दो परिभाषाएं हैं शान्ति आत्मसमर्पण। _END           14                   21                 \n",
       "118633  ted        everything is reliant on these computers working                                                                               START_ इन कंप्यूटरों पर सब कुछ निर्भर है _END                                                                              7                    9                  \n",
       "113495  tides      parliament does not control the government                                                                                     START_ संसद का सरकार पपर नियंत्रण नपहीं रहता _END                                                                          6                    9                  \n",
       "29783   tides      race equality new laws                                                                                                         START_ नये कानून नस्ली समानता _END                                                                                         4                    6                  \n",
       "111804  tides      the provision would not affect the power of parliament to make laws in respect of income from professions etc lrb article rrb  START_ व्यवसायों आदि से होने वाली आय के बारे में विधि बनाने की संसद की शक्ति पर उपबंध का प्रभाव नहीं पड़ेगा अनुच्छेद _END  22                   24                 "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4905, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32971, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(max_length_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45291, 52937)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99850</th>\n",
       "      <td>ted</td>\n",
       "      <td>i dont want to make this as a corporate entity</td>\n",
       "      <td>START_ मैं अपने इस प्रयास को कोई कॉरपोरेट शक्ल नहीं देना चाहता _END</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63048</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>should be defined</td>\n",
       "      <td>START_ परिभाषित हो _END</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80981</th>\n",
       "      <td>ted</td>\n",
       "      <td>photographing and blogging</td>\n",
       "      <td>START_ फोटोphoto लेना और लिखना _END</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34223</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>with this they also keep an eye on the election</td>\n",
       "      <td>START_ इसके साथ ही वह शहर में होने वाले चुनावों पर भी नज़र रखता है। _END</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56625</th>\n",
       "      <td>ted</td>\n",
       "      <td>the brain scans showed activation in a part of the brain</td>\n",
       "      <td>START_ मस्तिष्क स्कैन से मस्तिष्क का एक हिस्सा सक्रियण दिखा _END</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42318</th>\n",
       "      <td>ted</td>\n",
       "      <td>if my work was nice enough to show it to people</td>\n",
       "      <td>START_ कि मेरा काम लोगों को दिखाने लायक था कि नहीं _END</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38775</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the chinese civilization is older than sixth th century</td>\n",
       "      <td>START_ चीन की सभ्यता एवम् संस्कृति छठी शताब्दी से भी पुरानी है। _END</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44769</th>\n",
       "      <td>ted</td>\n",
       "      <td>and the separation from your loved ones</td>\n",
       "      <td>START_ छटपटाहट है अपनों से दूर होने की _END</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122490</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>simple machines forum ashtank software part of the advertising campaign to promote hindi</td>\n",
       "      <td>START_ सरल मशीन मंच simple machine forum अष्टांक सॉफ़्टवेयर के हिन्दी प्रचार प्रसार अभियान का एक अंग है । _END</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72874</th>\n",
       "      <td>ted</td>\n",
       "      <td>but what perhaps some of you dont realize</td>\n",
       "      <td>START_ लेकिन आप में से कुछ लोगो यह एहसास नहीं होगा _END</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                                                          english_sentence                                                                                                  hindi_sentence  length_eng_sentence  length_hin_sentence\n",
       "99850   ted        i dont want to make this as a corporate entity                                            START_ मैं अपने इस प्रयास को कोई कॉरपोरेट शक्ल नहीं देना चाहता _END                                             10                   13                 \n",
       "63048   indic2012  should be defined                                                                         START_ परिभाषित हो _END                                                                                         3                    4                  \n",
       "80981   ted        photographing and blogging                                                                START_ फोटोphoto लेना और लिखना _END                                                                             3                    6                  \n",
       "34223   indic2012  with this they also keep an eye on the election                                           START_ इसके साथ ही वह शहर में होने वाले चुनावों पर भी नज़र रखता है। _END                                        10                   16                 \n",
       "56625   ted        the brain scans showed activation in a part of the brain                                  START_ मस्तिष्क स्कैन से मस्तिष्क का एक हिस्सा सक्रियण दिखा _END                                                11                   11                 \n",
       "42318   ted        if my work was nice enough to show it to people                                           START_ कि मेरा काम लोगों को दिखाने लायक था कि नहीं _END                                                         11                   12                 \n",
       "38775   indic2012  the chinese civilization is older than sixth th century                                   START_ चीन की सभ्यता एवम् संस्कृति छठी शताब्दी से भी पुरानी है। _END                                            9                    13                 \n",
       "44769   ted        and the separation from your loved ones                                                   START_ छटपटाहट है अपनों से दूर होने की _END                                                                     7                    9                  \n",
       "122490  indic2012  simple machines forum ashtank software part of the advertising campaign to promote hindi  START_ सरल मशीन मंच simple machine forum अष्टांक सॉफ़्टवेयर के हिन्दी प्रचार प्रसार अभियान का एक अंग है । _END  13                   20                 \n",
       "72874   ted        but what perhaps some of you dont realize                                                 START_ लेकिन आप में से कुछ लोगो यह एहसास नहीं होगा _END                                                         8                    12                 "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26376,), (6595,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49713     “what are you doing here                                                                            \n",
       "22541     category main jamboodweep                                                                           \n",
       "473       these messages were started from aadam                                                              \n",
       "120500    north west                                                                                          \n",
       "4722      and guess what                                                                                      \n",
       "               ...                                                                                            \n",
       "117495    public relations office                                                                             \n",
       "63620     viii cases of sexual intercourse with immoral women                                                 \n",
       "123273    howeverit was projected in such a way that to most buddhist it is not acceptable and very unpleasant\n",
       "107768    each grill of the sheet is form with great work of mosaic                                           \n",
       "5930      type i and type ii are two main variations in presentation of diabetes                              \n",
       "Name: english_sentence, Length: 26376, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49713     START_ “तब यहाँ क्या कर रहे हो _END                                                                        \n",
       "22541     START_ श्रेणीनैऋत्य जंबुद्वीप _END                                                                         \n",
       "473       START_ इन संदेशों का शुभारम्भ आदम से हुआ था। _END                                                          \n",
       "120500    START_ उत्तर पश्चिम सीमांत प्रान्त _END                                                                    \n",
       "4722      START_ और इसका नतीजा _END                                                                                  \n",
       "                    ...                                                                                              \n",
       "117495    START_ जनसम्पर्क कार्यालय ग्वालियर _END                                                                    \n",
       "63620     START_ पतित स्त्रियों के साथ मैथुन के मामले _END                                                           \n",
       "123273    START_ लेकिन इसे इस तरीके से पेश किया गया है जिसे ज़्यादातर बौद्ध अस्वीकार्य और बेहद अप्रिय मानते हैं। _END\n",
       "107768    START_ हरेक फलक की जाली पच्चीकारी के महीन कार्य से गठित है। _END                                           \n",
       "5930      START_ मधुमेह के दो मुख़्य प्रकार हैं टाइप ई तथा टाइप ईई _END                                              \n",
       "Name: hindi_sentence, Length: 26376, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 18:28:38.054359: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.086522: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.086771: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.088308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.088510: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.088692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.140551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.140756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.140932: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-30 18:28:38.141070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-30 18:28:38.245085: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 300)            1358730   ['input_1[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 300)            1588140   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 300),                721200    ['embedding[0][0]']           \n",
      "                              (None, 300),                                                        \n",
      "                              (None, 300)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 300),          721200    ['embedding_1[0][0]',         \n",
      "                              (None, 300),                           'lstm[0][1]',                \n",
      "                              (None, 300)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 52938)          1593433   ['lstm_1[0][0]']              \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 46845438 (178.70 MB)\n",
      "Trainable params: 46845438 (178.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 64\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20131/2713035456.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 18:28:43.681897: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_36/output/_23'\n",
      "2024-05-30 18:28:44.442648: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-05-30 18:28:44.878738: I external/local_xla/xla/service/service.cc:168] XLA service 0x758c99118d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-30 18:28:44.878773: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-05-30 18:28:44.990819: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717073925.195874   20278 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 156s 365ms/step - loss: 7.3581 - val_loss: 7.0269\n",
      "Epoch 2/80\n",
      "412/412 [==============================] - 149s 362ms/step - loss: 6.9725 - val_loss: 7.0316\n",
      "Epoch 3/80\n",
      "412/412 [==============================] - 150s 363ms/step - loss: 6.9395 - val_loss: 7.0169\n",
      "Epoch 4/80\n",
      "412/412 [==============================] - 149s 363ms/step - loss: 6.9173 - val_loss: 6.9978\n",
      "Epoch 5/80\n",
      "412/412 [==============================] - 146s 355ms/step - loss: 6.8894 - val_loss: 6.9621\n",
      "Epoch 6/80\n",
      "412/412 [==============================] - 147s 357ms/step - loss: 6.8128 - val_loss: 6.8627\n",
      "Epoch 7/80\n",
      "412/412 [==============================] - 147s 358ms/step - loss: 6.7037 - val_loss: 6.7632\n",
      "Epoch 8/80\n",
      "412/412 [==============================] - 147s 356ms/step - loss: 6.5887 - val_loss: 6.6787\n",
      "Epoch 9/80\n",
      "412/412 [==============================] - 147s 356ms/step - loss: 6.4839 - val_loss: 6.5816\n",
      "Epoch 10/80\n",
      "412/412 [==============================] - 147s 356ms/step - loss: 6.3909 - val_loss: 6.5190\n",
      "Epoch 11/80\n",
      "412/412 [==============================] - 147s 356ms/step - loss: 6.3152 - val_loss: 6.4666\n",
      "Epoch 12/80\n",
      "412/412 [==============================] - 147s 357ms/step - loss: 6.2480 - val_loss: 6.4443\n",
      "Epoch 13/80\n",
      "412/412 [==============================] - 147s 357ms/step - loss: 6.1840 - val_loss: 6.3908\n",
      "Epoch 14/80\n",
      "412/412 [==============================] - 153s 372ms/step - loss: 6.1236 - val_loss: 6.3509\n",
      "Epoch 15/80\n",
      "412/412 [==============================] - 153s 370ms/step - loss: 6.0615 - val_loss: 6.3159\n",
      "Epoch 16/80\n",
      "412/412 [==============================] - 153s 371ms/step - loss: 6.0032 - val_loss: 6.2782\n",
      "Epoch 17/80\n",
      "412/412 [==============================] - 151s 367ms/step - loss: 5.9473 - val_loss: 6.2349\n",
      "Epoch 18/80\n",
      "412/412 [==============================] - 153s 371ms/step - loss: 5.8860 - val_loss: 6.2046\n",
      "Epoch 19/80\n",
      "412/412 [==============================] - 164s 398ms/step - loss: 5.8276 - val_loss: 6.1755\n",
      "Epoch 20/80\n",
      "412/412 [==============================] - 152s 370ms/step - loss: 5.7698 - val_loss: 6.1570\n",
      "Epoch 21/80\n",
      "412/412 [==============================] - 153s 371ms/step - loss: 5.7140 - val_loss: 6.1400\n",
      "Epoch 22/80\n",
      "412/412 [==============================] - 153s 372ms/step - loss: 5.6567 - val_loss: 6.0836\n",
      "Epoch 23/80\n",
      "412/412 [==============================] - 153s 371ms/step - loss: 5.6016 - val_loss: 6.0606\n",
      "Epoch 24/80\n",
      "412/412 [==============================] - 152s 370ms/step - loss: 5.5446 - val_loss: 6.0774\n",
      "Epoch 25/80\n",
      "412/412 [==============================] - 157s 381ms/step - loss: 5.4888 - val_loss: 6.0249\n",
      "Epoch 26/80\n",
      "412/412 [==============================] - 158s 383ms/step - loss: 5.4325 - val_loss: 5.9959\n",
      "Epoch 27/80\n",
      "412/412 [==============================] - 158s 384ms/step - loss: 5.3754 - val_loss: 5.9659\n",
      "Epoch 28/80\n",
      "412/412 [==============================] - 153s 372ms/step - loss: 5.3191 - val_loss: 5.9405\n",
      "Epoch 29/80\n",
      "412/412 [==============================] - 154s 374ms/step - loss: 5.2631 - val_loss: 5.9400\n",
      "Epoch 30/80\n",
      "412/412 [==============================] - 154s 373ms/step - loss: 5.2079 - val_loss: 5.9041\n",
      "Epoch 31/80\n",
      "412/412 [==============================] - 154s 375ms/step - loss: 5.1549 - val_loss: 5.9029\n",
      "Epoch 32/80\n",
      "412/412 [==============================] - 157s 381ms/step - loss: 5.1015 - val_loss: 5.8711\n",
      "Epoch 33/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 5.0482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 19:51:47.104286: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-05-30 19:51:47.104353: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 157s 382ms/step - loss: 5.0482 - val_loss: 5.8678\n",
      "Epoch 34/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.9974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 19:54:25.312589: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 160s 389ms/step - loss: 4.9974 - val_loss: 5.8656\n",
      "Epoch 35/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.9447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 19:57:09.914995: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-05-30 19:57:09.915089: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 163s 396ms/step - loss: 4.9447 - val_loss: 5.8441\n",
      "Epoch 36/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.8941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 19:59:46.802266: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-05-30 19:59:46.802422: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 158s 384ms/step - loss: 4.8941 - val_loss: 5.8477\n",
      "Epoch 37/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.8430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:02:25.684060: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 159s 386ms/step - loss: 4.8430 - val_loss: 5.8284\n",
      "Epoch 38/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.7921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:05:00.181413: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 154s 374ms/step - loss: 4.7921 - val_loss: 5.8293\n",
      "Epoch 39/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.7424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:07:40.342961: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 161s 390ms/step - loss: 4.7424 - val_loss: 5.8346\n",
      "Epoch 40/80\n",
      "412/412 [==============================] - 151s 367ms/step - loss: 4.6931 - val_loss: 5.8295\n",
      "Epoch 41/80\n",
      "412/412 [==============================] - 155s 376ms/step - loss: 4.6445 - val_loss: 5.8149\n",
      "Epoch 42/80\n",
      "412/412 [==============================] - 162s 394ms/step - loss: 4.5947 - val_loss: 5.8164\n",
      "Epoch 43/80\n",
      "412/412 [==============================] - 158s 384ms/step - loss: 4.5430 - val_loss: 5.8014\n",
      "Epoch 44/80\n",
      "412/412 [==============================] - 160s 388ms/step - loss: 4.4932 - val_loss: 5.8173\n",
      "Epoch 45/80\n",
      "412/412 [==============================] - 158s 384ms/step - loss: 4.4452 - val_loss: 5.7993\n",
      "Epoch 46/80\n",
      "412/412 [==============================] - 162s 394ms/step - loss: 4.3947 - val_loss: 5.8072\n",
      "Epoch 47/80\n",
      "412/412 [==============================] - 160s 388ms/step - loss: 4.3426 - val_loss: 5.8189\n",
      "Epoch 48/80\n",
      "412/412 [==============================] - 164s 398ms/step - loss: 4.2932 - val_loss: 5.8042\n",
      "Epoch 49/80\n",
      "412/412 [==============================] - 162s 393ms/step - loss: 4.2420 - val_loss: 5.7949\n",
      "Epoch 50/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.1902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:36:51.070782: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 157s 381ms/step - loss: 4.1902 - val_loss: 5.8100\n",
      "Epoch 51/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.1375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:39:32.210491: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 163s 395ms/step - loss: 4.1375 - val_loss: 5.8152\n",
      "Epoch 52/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.0864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:42:19.134620: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 167s 406ms/step - loss: 4.0864 - val_loss: 5.8111\n",
      "Epoch 53/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 4.0352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:44:56.383351: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 157s 382ms/step - loss: 4.0352 - val_loss: 5.8125\n",
      "Epoch 54/80\n",
      "412/412 [==============================] - 161s 391ms/step - loss: 3.9800 - val_loss: 5.8150\n",
      "Epoch 55/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.9274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:50:25.056279: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 169s 410ms/step - loss: 3.9274 - val_loss: 5.8318\n",
      "Epoch 56/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.8724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:53:11.892189: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 167s 405ms/step - loss: 3.8724 - val_loss: 5.8377\n",
      "Epoch 57/80\n",
      "412/412 [==============================] - 160s 388ms/step - loss: 3.8175 - val_loss: 5.8351\n",
      "Epoch 58/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.7631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:58:33.596151: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 164s 398ms/step - loss: 3.7631 - val_loss: 5.8324\n",
      "Epoch 59/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.7083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:01:17.047214: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 159s 386ms/step - loss: 3.7083 - val_loss: 5.8319\n",
      "Epoch 60/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.6540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:03:52.978174: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 156s 379ms/step - loss: 3.6540 - val_loss: 5.8451\n",
      "Epoch 61/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.5987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:06:27.424959: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 158s 384ms/step - loss: 3.5987 - val_loss: 5.8573\n",
      "Epoch 62/80\n",
      "412/412 [==============================] - 164s 397ms/step - loss: 3.5447 - val_loss: 5.8734\n",
      "Epoch 63/80\n",
      "412/412 [==============================] - 163s 395ms/step - loss: 3.4887 - val_loss: 5.8744\n",
      "Epoch 64/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.4319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:14:37.197100: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 162s 394ms/step - loss: 3.4319 - val_loss: 5.9018\n",
      "Epoch 65/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.3793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:17:20.427366: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 162s 393ms/step - loss: 3.3793 - val_loss: 5.8966\n",
      "Epoch 66/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.3244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:20:05.626253: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-05-30 21:20:05.626416: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 168s 407ms/step - loss: 3.3244 - val_loss: 5.9096\n",
      "Epoch 67/80\n",
      "412/412 [==============================] - 162s 395ms/step - loss: 3.2681 - val_loss: 5.9131\n",
      "Epoch 68/80\n",
      "412/412 [==============================] - 165s 400ms/step - loss: 3.2147 - val_loss: 5.9376\n",
      "Epoch 69/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.1603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:28:21.164438: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 165s 402ms/step - loss: 3.1603 - val_loss: 5.9471\n",
      "Epoch 70/80\n",
      "412/412 [==============================] - 162s 394ms/step - loss: 3.1053 - val_loss: 5.9683\n",
      "Epoch 71/80\n",
      "412/412 [==============================] - ETA: 0s - loss: 3.0493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:33:45.508924: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 271052800 bytes after encountering the first element of size 271052800 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 161s 392ms/step - loss: 3.0493 - val_loss: 5.9669\n",
      "Epoch 72/80\n",
      "412/412 [==============================] - 166s 404ms/step - loss: 2.9944 - val_loss: 5.9960\n",
      "Epoch 73/80\n",
      "412/412 [==============================] - 161s 391ms/step - loss: 2.9400 - val_loss: 6.0251\n",
      "Epoch 74/80\n",
      "412/412 [==============================] - 159s 386ms/step - loss: 2.8862 - val_loss: 6.0490\n",
      "Epoch 75/80\n",
      "412/412 [==============================] - 161s 392ms/step - loss: 2.8321 - val_loss: 6.0529\n",
      "Epoch 76/80\n",
      "412/412 [==============================] - 163s 396ms/step - loss: 2.7773 - val_loss: 6.0646\n",
      "Epoch 77/80\n",
      "412/412 [==============================] - 163s 396ms/step - loss: 2.7219 - val_loss: 6.0891\n",
      "Epoch 78/80\n",
      "412/412 [==============================] - 157s 380ms/step - loss: 2.6680 - val_loss: 6.1085\n",
      "Epoch 79/80\n",
      "412/412 [==============================] - 161s 392ms/step - loss: 2.6151 - val_loss: 6.1266\n",
      "Epoch 80/80\n",
      "412/412 [==============================] - 161s 391ms/step - loss: 2.5607 - val_loss: 6.1327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x758d73c91ff0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('nmt_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Input English sentence: “what are you doing here\n",
      "Actual Hindi Translation:  “तब यहाँ क्या कर रहे हो \n",
      "Predicted Hindi Translation:  क्या यहाँ कर रहे हैं \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m (input_seq, actual_output), _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_gen)\n\u001b[1;32m      3\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m decode_sequence(input_seq)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input English sentence: even now during dark nights malay boats visit these shores with smuggled goods\n",
      "Actual Hindi Translation:  अब भी मलाया की अनेक नावें यहां के समुद्रतट पर तस्करी का माल लेकर आती हैं \n",
      "Predicted Hindi Translation:  अब इन में से विभिन्न भागों के साथ विभिन्न उद्यो\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Input English sentence: it is build by mugal king shahjaha memory of his wife mumtaj mahal\n",
      "Actual Hindi Translation:  इसका निर्माण मुगल सम्राट शाहजहाँ ने अपनी पत्नी मुमताज महल की याद में करवाया था। \n",
      "Predicted Hindi Translation:  इसका निर्माण निर्माण निर्माण कर जो मुगल पत्नी मु\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Input English sentence: and guess what\n",
      "Actual Hindi Translation:  और इसका नतीजा \n",
      "Predicted Hindi Translation:  और उदाहरण के लिए \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roronoa/ai/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_model.save('../models/english_to_hindi_translator/encoder_model_e2h.h5')\n",
    "decoder_model.save('../models/english_to_hindi_translator/decoder_model_e2h.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the tokenizers\n",
    "with open('../models/english_to_hindi_translator/english_tokenizer_e2h.pkl', 'wb') as f:\n",
    "    pickle.dump(input_token_index, f)\n",
    "\n",
    "with open('../models/english_to_hindi_translator/hindi_tokenizer_e2h.pkl', 'wb') as f:\n",
    "    pickle.dump(target_token_index, f)\n",
    "\n",
    "# Save the reverse tokenizers\n",
    "with open('../models/english_to_hindi_translator/reverse_english_tokenizer_e2h.pkl', 'wb') as f:\n",
    "    pickle.dump(reverse_input_char_index, f)\n",
    "\n",
    "with open('../models/english_to_hindi_translator/reverse_hindi_tokenizer_e2h.pkl', 'wb') as f:\n",
    "    pickle.dump(reverse_target_char_index, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 01:35:44.061545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-31 01:35:44.061602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-31 01:35:44.062866: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-31 01:35:44.072814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 01:35:45.213107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-05-31 01:35:47.851716: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.897113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.897541: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.899805: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.900023: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.900203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.974496: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.974707: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.974895: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 01:35:47.975075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-31 01:35:48.154293: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 01:35:55.273083: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load the models\n",
    "encoder_model = load_model('../models/english_to_hindi_translator/encoder_model_e2h.h5')\n",
    "decoder_model = load_model('../models/english_to_hindi_translator/decoder_model_e2h.h5')\n",
    "\n",
    "\n",
    "with open('../models/english_to_hindi_translator/english_tokenizer_e2h.pkl', 'rb') as f:\n",
    "    input_token_index = pickle.load(f)\n",
    "\n",
    "with open('../models/english_to_hindi_translator/hindi_tokenizer_e2h.pkl', 'rb') as f:\n",
    "    target_token_index = pickle.load(f)\n",
    "\n",
    "with open('../models/english_to_hindi_translator/reverse_english_tokenizer_e2h.pkl', 'rb') as f:\n",
    "    reverse_input_char_index = pickle.load(f)\n",
    "\n",
    "with open('../models/english_to_hindi_translator/reverse_hindi_tokenizer_e2h.pkl', 'rb') as f:\n",
    "    reverse_target_char_index = pickle.load(f)\n",
    "\n",
    "max_length_src = 20  \n",
    "latent_dim = 300\n",
    "num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "def translate_sentence(input_sentence):\n",
    "    input_seq = [input_token_index.get(word, 0) for word in input_sentence.split()]\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences([input_seq], maxlen=max_length_src, padding='post')\n",
    "\n",
    "    # Encode the input as state vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index.get(sampled_token_index, '')\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character\n",
    "        if sampled_char == '_END' or len(decoded_sentence) > max_length_src:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence.append(sampled_char)\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(decoded_sentence)\n",
    "\n",
    "# Example usage\n",
    "import random \n",
    "random_index = randint\n",
    "print(translate_sentence(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
